{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and combining data\n",
    "#### Meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading meteo data\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "years = ['2022']\n",
    "base_url_meteo = 'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_{}{}.csv'\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        url = base_url_meteo.format(year, quarter)\n",
    "        df = pd.read_csv(url)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into a single dataframe\n",
    "meteo_combined_df = pd.concat(dfs, ignore_index=True)\n",
    "meteo_combined_df.head()\n",
    "\n",
    "del dfs # deleting the individual meteo datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.048027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.985849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.950322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.949550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.952268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED  Month  Day  Hour  \\\n",
       "0        0.0           0.0      -169.0          0.43      1    1     0   \n",
       "1        0.0           0.0      -170.0          0.33      1    1     0   \n",
       "2        0.0           0.0      -167.0          0.46      1    1     0   \n",
       "3        0.0           0.0      -160.0          0.52      1    1     0   \n",
       "4        0.0           0.0      -166.0          0.51      1    1     0   \n",
       "\n",
       "   LC_TEMP_QCL3  \n",
       "0     13.048027  \n",
       "1     12.985849  \n",
       "2     12.950322  \n",
       "3     12.949550  \n",
       "4     12.952268  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns we won't use\n",
    "columns_to_keep = ['LC_RAININ', 'LC_DAILYRAIN', 'LC_WINDDIR', 'LC_WINDSPEED', 'LC_TEMP_QCL3', 'Month', 'Day', 'Hour']  #there's less columns we keep than drop\n",
    "columns_to_drop = set(meteo_combined_df.columns) - set(columns_to_keep)\n",
    "meteo_combined_df.drop(columns=columns_to_drop, inplace=True)\n",
    "meteo_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC_RAININ       0.056770\n",
      "LC_DAILYRAIN    0.056770\n",
      "LC_WINDDIR      0.056770\n",
      "LC_WINDSPEED    0.056770\n",
      "Month           0.000000\n",
      "Day             0.000000\n",
      "Hour            0.000000\n",
      "LC_TEMP_QCL3    0.062285\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check for percentage of missing values in each column\n",
    "print(meteo_combined_df.isnull().sum() / len(meteo_combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC_RAININ       0\n",
      "LC_DAILYRAIN    0\n",
      "LC_WINDDIR      0\n",
      "LC_WINDSPEED    0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "LC_TEMP_QCL3    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing values in the original DataFrame\n",
    "meteo_combined_df.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "print(meteo_combined_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.546880e+06\n",
      "mean     1.319783e-03\n",
      "std      6.177559e-03\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.540000e-01\n",
      "Name: LC_DAILYRAIN, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate summary statistics for daily rain sum\n",
    "summary_stats = meteo_combined_df['LC_DAILYRAIN'].describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of non-zero values: 0.17391488548517364\n"
     ]
    }
   ],
   "source": [
    "# Count the number of non-zero values in the 'LC_DAILYRAIN' column\n",
    "nonzero_count = np.count_nonzero(meteo_combined_df['LC_DAILYRAIN'])\n",
    "\n",
    "# Display the fraction of non-zero values\n",
    "print(\"Fraction of non-zero values:\", nonzero_count/len(meteo_combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-18.197324</td>\n",
       "      <td>0.389565</td>\n",
       "      <td>13.100358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-16.227891</td>\n",
       "      <td>0.222602</td>\n",
       "      <td>12.669197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-13.710884</td>\n",
       "      <td>0.217194</td>\n",
       "      <td>12.520271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16.401361</td>\n",
       "      <td>0.178248</td>\n",
       "      <td>12.386194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.268707</td>\n",
       "      <td>0.237670</td>\n",
       "      <td>12.080706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-3.539116</td>\n",
       "      <td>0.143759</td>\n",
       "      <td>11.227068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.875850</td>\n",
       "      <td>0.100765</td>\n",
       "      <td>10.796072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-10.292517</td>\n",
       "      <td>0.140680</td>\n",
       "      <td>10.694374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.911565</td>\n",
       "      <td>0.184677</td>\n",
       "      <td>10.336767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.236395</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>10.923896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-2.908163</td>\n",
       "      <td>0.472908</td>\n",
       "      <td>11.597301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.629252</td>\n",
       "      <td>0.481156</td>\n",
       "      <td>12.815721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-21.848639</td>\n",
       "      <td>0.475714</td>\n",
       "      <td>13.765421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-12.353741</td>\n",
       "      <td>0.512075</td>\n",
       "      <td>14.164516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.780612</td>\n",
       "      <td>0.296905</td>\n",
       "      <td>13.989589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>28.365646</td>\n",
       "      <td>0.259184</td>\n",
       "      <td>13.347069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.314626</td>\n",
       "      <td>0.300561</td>\n",
       "      <td>12.779698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>12.636054</td>\n",
       "      <td>0.150493</td>\n",
       "      <td>12.036331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8.806122</td>\n",
       "      <td>0.241293</td>\n",
       "      <td>11.681998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.637755</td>\n",
       "      <td>0.438861</td>\n",
       "      <td>11.784593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-12.833333</td>\n",
       "      <td>0.501582</td>\n",
       "      <td>11.963431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.110544</td>\n",
       "      <td>0.444915</td>\n",
       "      <td>11.994651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.622449</td>\n",
       "      <td>0.531173</td>\n",
       "      <td>11.998079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.607143</td>\n",
       "      <td>0.472789</td>\n",
       "      <td>11.990756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Day  Hour  LC_DAILYRAIN  LC_RAININ  LC_WINDDIR  LC_WINDSPEED  \\\n",
       "0       1    1     0      0.000360   0.000003  -18.197324      0.389565   \n",
       "1       1    1     1      0.000000   0.000007  -16.227891      0.222602   \n",
       "2       1    1     2      0.000000   0.000009  -13.710884      0.217194   \n",
       "3       1    1     3      0.000000   0.000000  -16.401361      0.178248   \n",
       "4       1    1     4      0.000000   0.000000  -10.268707      0.237670   \n",
       "5       1    1     5      0.000007   0.000005   -3.539116      0.143759   \n",
       "6       1    1     6      0.000010   0.000000    4.875850      0.100765   \n",
       "7       1    1     7      0.000015   0.000003  -10.292517      0.140680   \n",
       "8       1    1     8      0.000020   0.000000   -7.911565      0.184677   \n",
       "9       1    1     9      0.000022   0.000000  -10.236395      0.396973   \n",
       "10      1    1    10      0.000031   0.000003   -2.908163      0.472908   \n",
       "11      1    1    11      0.000031   0.000000  -12.629252      0.481156   \n",
       "12      1    1    12      0.000031   0.000000  -21.848639      0.475714   \n",
       "13      1    1    13      0.000039   0.000003  -12.353741      0.512075   \n",
       "14      1    1    14      0.000041   0.000000   -1.780612      0.296905   \n",
       "15      1    1    15      0.000044   0.000009   28.365646      0.259184   \n",
       "16      1    1    16      0.000051   0.000000   17.314626      0.300561   \n",
       "17      1    1    17      0.000051   0.000002   12.636054      0.150493   \n",
       "18      1    1    18      0.000051   0.000003    8.806122      0.241293   \n",
       "19      1    1    19      0.000051   0.000000   -3.637755      0.438861   \n",
       "20      1    1    20      0.000051   0.000005  -12.833333      0.501582   \n",
       "21      1    1    21      0.000051   0.000000   -8.110544      0.444915   \n",
       "22      1    1    22      0.000051   0.000000  -18.622449      0.531173   \n",
       "23      1    1    23      0.000014   0.000000  -20.607143      0.472789   \n",
       "\n",
       "    LC_TEMP_QCL3  \n",
       "0      13.100358  \n",
       "1      12.669197  \n",
       "2      12.520271  \n",
       "3      12.386194  \n",
       "4      12.080706  \n",
       "5      11.227068  \n",
       "6      10.796072  \n",
       "7      10.694374  \n",
       "8      10.336767  \n",
       "9      10.923896  \n",
       "10     11.597301  \n",
       "11     12.815721  \n",
       "12     13.765421  \n",
       "13     14.164516  \n",
       "14     13.989589  \n",
       "15     13.347069  \n",
       "16     12.779698  \n",
       "17     12.036331  \n",
       "18     11.681998  \n",
       "19     11.784593  \n",
       "20     11.963431  \n",
       "21     11.994651  \n",
       "22     11.998079  \n",
       "23     11.990756  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per hour\n",
    "\n",
    "# Specify the aggregation function for each column\n",
    "  # for LC_DAILYRAIN we take the last value because it's cumulative, for other columns the mean\n",
    "aggregations = {\n",
    "    'LC_DAILYRAIN': 'mean',  # Select the last value for 'LC_DAILYRAIN' ###TAKE MEAN FOR NOW TO MAKE THE GRAPHS LOOK OK\n",
    "    'LC_RAININ': 'mean',  \n",
    "    'LC_WINDDIR': 'mean',\n",
    "    'LC_WINDDIR': 'mean', \n",
    "    'LC_WINDSPEED': 'mean', \n",
    "    'LC_TEMP_QCL3': 'mean'\n",
    "}\n",
    "\n",
    "# Perform the groupby aggregation\n",
    "meteo_per_hour = meteo_combined_df.groupby(['Month', 'Day', 'Hour']).agg(aggregations).reset_index()\n",
    "meteo_per_hour.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-6.263419</td>\n",
       "      <td>0.324702</td>\n",
       "      <td>12.194145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-28.223994</td>\n",
       "      <td>0.707815</td>\n",
       "      <td>11.893159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>-34.624291</td>\n",
       "      <td>0.650430</td>\n",
       "      <td>9.539620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>-25.189413</td>\n",
       "      <td>0.326204</td>\n",
       "      <td>6.768886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-43.943098</td>\n",
       "      <td>0.602983</td>\n",
       "      <td>3.889968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-17.698413</td>\n",
       "      <td>0.270271</td>\n",
       "      <td>3.660429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-25.585955</td>\n",
       "      <td>0.598921</td>\n",
       "      <td>3.926373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-8.783447</td>\n",
       "      <td>0.606362</td>\n",
       "      <td>3.672283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-28.891440</td>\n",
       "      <td>0.527744</td>\n",
       "      <td>4.340409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>7.590774</td>\n",
       "      <td>0.126139</td>\n",
       "      <td>0.243363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>0.099418</td>\n",
       "      <td>1.718569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-4.560020</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>2.754150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-8.054918</td>\n",
       "      <td>0.086016</td>\n",
       "      <td>2.371137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.979663</td>\n",
       "      <td>0.060821</td>\n",
       "      <td>2.939710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.036139</td>\n",
       "      <td>0.114262</td>\n",
       "      <td>2.191837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Day  LC_DAILYRAIN  LC_RAININ  LC_WINDDIR  LC_WINDSPEED  \\\n",
       "0       1    1      0.000000   0.000002   -6.263419      0.324702   \n",
       "1       1    2      0.000000   0.000671  -28.223994      0.707815   \n",
       "2       1    3      0.001000   0.000729  -34.624291      0.650430   \n",
       "3       1    4      0.000000   0.000454  -25.189413      0.326204   \n",
       "4       1    5      0.000000   0.000127  -43.943098      0.602983   \n",
       "5       1    6      0.000000   0.000022  -17.698413      0.270271   \n",
       "6       1    7      0.000000   0.000174  -25.585955      0.598921   \n",
       "7       1    8      0.003000   0.000664   -8.783447      0.606362   \n",
       "8       1    9      0.000000   0.000122  -28.891440      0.527744   \n",
       "9       1   10      0.000000   0.000008    7.590774      0.126139   \n",
       "10      1   11      0.000000   0.000003    0.788761      0.099418   \n",
       "11      1   12      0.000000   0.000004   -4.560020      0.063572   \n",
       "12      1   13      0.000000   0.000003   -8.054918      0.086016   \n",
       "13      1   14      0.000000   0.000007    0.979663      0.060821   \n",
       "14      1   15      0.000000   0.000000   21.036139      0.114262   \n",
       "\n",
       "    LC_TEMP_QCL3  \n",
       "0      12.194145  \n",
       "1      11.893159  \n",
       "2       9.539620  \n",
       "3       6.768886  \n",
       "4       3.889968  \n",
       "5       3.660429  \n",
       "6       3.926373  \n",
       "7       3.672283  \n",
       "8       4.340409  \n",
       "9       0.243363  \n",
       "10      1.718569  \n",
       "11      2.754150  \n",
       "12      2.371137  \n",
       "13      2.939710  \n",
       "14      2.191837  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per day\n",
    "\n",
    "# still the same \"aggregations\" as before\n",
    "meteo_per_day = meteo_combined_df.groupby(['Month', 'Day']).agg(aggregations).reset_index()\n",
    "meteo_per_day.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-16.334089</td>\n",
       "      <td>0.336535</td>\n",
       "      <td>4.698144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-25.171683</td>\n",
       "      <td>0.740747</td>\n",
       "      <td>6.923138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>12.190264</td>\n",
       "      <td>0.250732</td>\n",
       "      <td>8.113201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>3.643447</td>\n",
       "      <td>0.369271</td>\n",
       "      <td>10.704171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-9.022240</td>\n",
       "      <td>0.240475</td>\n",
       "      <td>15.572697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-6.516527</td>\n",
       "      <td>0.198103</td>\n",
       "      <td>18.171333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-9.940725</td>\n",
       "      <td>0.207655</td>\n",
       "      <td>19.854177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.364123</td>\n",
       "      <td>0.168515</td>\n",
       "      <td>21.508814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-6.154130</td>\n",
       "      <td>0.172836</td>\n",
       "      <td>15.233993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-3.041569</td>\n",
       "      <td>0.194941</td>\n",
       "      <td>14.108411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-3.472709</td>\n",
       "      <td>0.335283</td>\n",
       "      <td>9.155312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-6.454915</td>\n",
       "      <td>0.338797</td>\n",
       "      <td>4.340581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  LC_DAILYRAIN  LC_RAININ  LC_WINDDIR  LC_WINDSPEED  LC_TEMP_QCL3\n",
       "0       1      0.001033   0.000112  -16.334089      0.336535      4.698144\n",
       "1       2      0.001257   0.000131  -25.171683      0.740747      6.923138\n",
       "2       3      0.000105   0.000010   12.190264      0.250732      8.113201\n",
       "3       4      0.000503   0.000054    3.643447      0.369271     10.704171\n",
       "4       5      0.000653   0.000076   -9.022240      0.240475     15.572697\n",
       "5       6      0.002190   0.000184   -6.516527      0.198103     18.171333\n",
       "6       7      0.000348   0.000220   -9.940725      0.207655     19.854177\n",
       "7       8      0.000357   0.000028    0.364123      0.168515     21.508814\n",
       "8       9      0.002336   0.000217   -6.154130      0.172836     15.233993\n",
       "9      10      0.001061   0.000067   -3.041569      0.194941     14.108411\n",
       "10     11      0.002276   0.000172   -3.472709      0.335283      9.155312\n",
       "11     12      0.003634   0.000185   -6.454915      0.338797      4.340581"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per month\n",
    "\n",
    "# still the same \"aggregations\" as before\n",
    "meteo_per_month = meteo_combined_df.groupby(['Month']).agg(aggregations).reset_index()\n",
    "meteo_per_month.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete combined dataframe\n",
    "del meteo_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframes (only needs to be ran once so comment it out)\n",
    "meteo_per_hour.to_csv('hourly_weatherdata_2022.csv', index=False)\n",
    "meteo_per_day.to_csv('daily_weatherdata_2022.csv', index=False)\n",
    "meteo_per_month.to_csv('monthly_weatherdata_2022.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- January "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs\n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the datasets for January\n",
    "combined_jan = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_jan['result_timestamp'] = pd.to_datetime(combined_jan['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_jan['result_date'] = combined_jan['result_timestamp'].dt.date\n",
    "combined_jan['result_month'] = combined_jan['result_timestamp'].dt.month\n",
    "combined_jan['result_day'] = combined_jan['result_timestamp'].dt.day\n",
    "combined_jan['result_hour'] = combined_jan['result_timestamp'].dt.hour\n",
    "combined_jan['result_minute'] = combined_jan['result_timestamp'].dt.minute\n",
    "\n",
    "combined_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data by day\n",
    "combined_jan = combined_jan.groupby(['result_date','description']).mean()\n",
    "combined_jan = combined_jan.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_jan.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_jan.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "print(combined_jan.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the datasets for February\n",
    "combined_feb = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_feb['result_timestamp'] = pd.to_datetime(combined_feb['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_feb['result_date'] = combined_feb['result_timestamp'].dt.date\n",
    "combined_feb['result_month'] = combined_feb['result_timestamp'].dt.month\n",
    "combined_feb['result_day'] = combined_feb['result_timestamp'].dt.day\n",
    "combined_feb['result_hour'] = combined_feb['result_timestamp'].dt.hour\n",
    "combined_feb['result_minute'] = combined_feb['result_timestamp'].dt.minute\n",
    "\n",
    "combined_feb.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data by day\n",
    "combined_feb = combined_feb.groupby(['result_date','description']).mean()\n",
    "combined_feb = combined_feb.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_feb.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_feb.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "print(combined_feb.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for March\n",
    "combined_mar = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_mar['result_timestamp'] = pd.to_datetime(combined_mar['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_mar['result_date'] = combined_mar['result_timestamp'].dt.date\n",
    "combined_mar['result_month'] = combined_mar['result_timestamp'].dt.month\n",
    "combined_mar['result_day'] = combined_mar['result_timestamp'].dt.day\n",
    "combined_mar['result_hour'] = combined_mar['result_timestamp'].dt.hour\n",
    "combined_mar['result_minute'] = combined_mar['result_timestamp'].dt.minute\n",
    "\n",
    "combined_mar.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_mar = combined_mar.groupby(['result_date','description']).mean()\n",
    "combined_mar = combined_mar.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_mar.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_mar.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_mar.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for April\n",
    "combined_apr = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_apr['result_timestamp'] = pd.to_datetime(combined_apr['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_apr['result_date'] = combined_apr['result_timestamp'].dt.date\n",
    "combined_apr['result_month'] = combined_apr['result_timestamp'].dt.month\n",
    "combined_apr['result_day'] = combined_apr['result_timestamp'].dt.day\n",
    "combined_apr['result_hour'] = combined_apr['result_timestamp'].dt.hour\n",
    "combined_apr['result_minute'] = combined_apr['result_timestamp'].dt.minute\n",
    "\n",
    "combined_apr.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_apr = combined_apr.groupby(['result_date','description']).mean()\n",
    "combined_apr = combined_apr.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_apr.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_apr.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_apr.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for May\n",
    "combined_may = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_may['result_timestamp'] = pd.to_datetime(combined_may['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_may['result_date'] = combined_may['result_timestamp'].dt.date\n",
    "combined_may['result_month'] = combined_may['result_timestamp'].dt.month\n",
    "combined_may['result_day'] = combined_may['result_timestamp'].dt.day\n",
    "combined_may['result_hour'] = combined_may['result_timestamp'].dt.hour\n",
    "combined_may['result_minute'] = combined_may['result_timestamp'].dt.minute\n",
    "\n",
    "combined_may.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_may = combined_may.groupby(['result_date','description']).mean()\n",
    "combined_may = combined_may.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_may.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_may.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_may.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for June\n",
    "combined_jun = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_jun['result_timestamp'] = pd.to_datetime(combined_jun['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_jun['result_date'] = combined_jun['result_timestamp'].dt.date\n",
    "combined_jun['result_month'] = combined_jun['result_timestamp'].dt.month\n",
    "combined_jun['result_day'] = combined_jun['result_timestamp'].dt.day\n",
    "combined_jun['result_hour'] = combined_jun['result_timestamp'].dt.hour\n",
    "combined_jun['result_minute'] = combined_jun['result_timestamp'].dt.minute\n",
    "\n",
    "combined_jun.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_jun = combined_jun.groupby(['result_date','description']).mean()\n",
    "combined_jun = combined_jun.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_jun.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_jun.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_jun.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for July\n",
    "combined_jul = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_jul['result_timestamp'] = pd.to_datetime(combined_jul['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_jul['result_date'] = combined_jul['result_timestamp'].dt.date\n",
    "combined_jul['result_month'] = combined_jul['result_timestamp'].dt.month\n",
    "combined_jul['result_day'] = combined_jul['result_timestamp'].dt.day\n",
    "combined_jul['result_hour'] = combined_jul['result_timestamp'].dt.hour\n",
    "combined_jul['result_minute'] = combined_jul['result_timestamp'].dt.minute\n",
    "\n",
    "combined_jul.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_jul = combined_jul.groupby(['result_date','description']).mean()\n",
    "combined_jul = combined_jul.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_jul.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_jul.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_jul.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for August\n",
    "combined_aug = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_aug['result_timestamp'] = pd.to_datetime(combined_aug['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_aug['result_date'] = combined_aug['result_timestamp'].dt.date\n",
    "combined_aug['result_month'] = combined_aug['result_timestamp'].dt.month\n",
    "combined_aug['result_day'] = combined_aug['result_timestamp'].dt.day\n",
    "combined_aug['result_hour'] = combined_aug['result_timestamp'].dt.hour\n",
    "combined_aug['result_minute'] = combined_aug['result_timestamp'].dt.minute\n",
    "\n",
    "combined_aug.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_aug = combined_aug.groupby(['result_date','description']).mean()\n",
    "combined_aug = combined_aug.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_aug.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_aug.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_aug.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for September\n",
    "combined_sep = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_sep['result_timestamp'] = pd.to_datetime(combined_sep['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_sep['result_date'] = combined_sep['result_timestamp'].dt.date\n",
    "combined_sep['result_month'] = combined_sep['result_timestamp'].dt.month\n",
    "combined_sep['result_day'] = combined_sep['result_timestamp'].dt.day\n",
    "combined_sep['result_hour'] = combined_sep['result_timestamp'].dt.hour\n",
    "combined_sep['result_minute'] = combined_sep['result_timestamp'].dt.minute\n",
    "\n",
    "combined_sep.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_sep = combined_sep.groupby(['result_date','description']).mean()\n",
    "combined_sep = combined_sep.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_sep.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_sep.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_sep.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for October\n",
    "combined_oct = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_oct['result_timestamp'] = pd.to_datetime(combined_oct['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_oct['result_date'] = combined_oct['result_timestamp'].dt.date\n",
    "combined_oct['result_month'] = combined_oct['result_timestamp'].dt.month\n",
    "combined_oct['result_day'] = combined_oct['result_timestamp'].dt.day\n",
    "combined_oct['result_hour'] = combined_oct['result_timestamp'].dt.hour\n",
    "combined_oct['result_minute'] = combined_oct['result_timestamp'].dt.minute\n",
    "\n",
    "combined_oct.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_oct = combined_oct.groupby(['result_date','description']).mean()\n",
    "combined_oct = combined_oct.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_oct.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_oct.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_oct.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for November\n",
    "combined_nov = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_nov['result_timestamp'] = pd.to_datetime(combined_nov['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_nov['result_date'] = combined_nov['result_timestamp'].dt.date\n",
    "combined_nov['result_month'] = combined_nov['result_timestamp'].dt.month\n",
    "combined_nov['result_day'] = combined_nov['result_timestamp'].dt.day\n",
    "combined_nov['result_hour'] = combined_nov['result_timestamp'].dt.hour\n",
    "combined_nov['result_minute'] = combined_nov['result_timestamp'].dt.minute\n",
    "\n",
    "combined_nov.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_nov = combined_nov.groupby(['result_date','description']).mean()\n",
    "combined_nov = combined_nov.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_nov.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_nov.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_nov.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url in urls:\n",
    "    df = pd.read_csv(url, header=0, sep=';')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL\n",
    "\n",
    "# Combining the datasets for December\n",
    "combined_dec = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the date, month, hour, minute of \"result_timestamp\"\n",
    "combined_dec['result_timestamp'] = pd.to_datetime(combined_dec['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "combined_dec['result_date'] = combined_dec['result_timestamp'].dt.date\n",
    "combined_dec['result_month'] = combined_dec['result_timestamp'].dt.month\n",
    "combined_dec['result_day'] = combined_dec['result_timestamp'].dt.day\n",
    "combined_dec['result_hour'] = combined_dec['result_timestamp'].dt.hour\n",
    "combined_dec['result_minute'] = combined_dec['result_timestamp'].dt.minute\n",
    "\n",
    "combined_dec.head()\n",
    "\n",
    "# aggregate the data by day\n",
    "combined_dec = combined_dec.groupby(['result_date','description']).mean()\n",
    "combined_dec = combined_dec.reset_index()\n",
    "columns_to_drop = ['result_hour', 'result_minute']\n",
    "combined_dec.drop(columns_to_drop, axis=1, inplace=True)\n",
    "combined_dec.head(150)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_dec.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the monthly datasets\n",
    "datasets = [combined_jan, combined_feb, combined_mar, combined_apr, combined_may, combined_jun, combined_jul, combined_aug, combined_sep, combined_oct, combined_nov, combined_dec]\n",
    "\n",
    "# Concatenate the datasets vertically\n",
    "combined_year = pd.concat(datasets, ignore_index=True)\n",
    "del datasets\n",
    "\n",
    "# Reset the index of the combined dataset\n",
    "combined_year = combined_year.reset_index()\n",
    "\n",
    "# Display the combined and sorted yearly dataset\n",
    "\n",
    "combined_year.head(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting file (only needs to be ran one time so comment it out)\n",
    "# combined_year.to_csv('combined_noisedata_2022.csv', index=False)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have exported the preprocessed dataframes for the noise and weather data of 2022, we can just use these files instead of loading all 112 files from the S3 bucket each time, as this takes a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_noise = pd.read_csv('combined_noisedata_2022.csv', header=0, sep=',')\n",
    "data_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weather = pd.read_csv('combined_weatherdata_2022.csv', header=0, sep=',')\n",
    "data_weather.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD PREPROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data from the S3 bucket (don't forget to pip install boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # meteo data\n",
    "# Q1_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q1.csv')\n",
    "# Q2_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q2.csv')\n",
    "# Q3_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q3.csv')\n",
    "# Q4_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: this is the 'old' noise data, don't run this\n",
    "\n",
    "# noise data\n",
    "# exp40_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp40_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp40_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp40_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp40_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp40_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp40_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp40_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp40_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_303910_mp-04-his-hears.csv', header=0, sep=';')\n",
    "\n",
    "# exp41_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp41_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp41_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp41_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp41_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp41_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp41_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp41_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp41_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_303910_mp-04-his-hears.csv', header=0, sep=';')\n",
    "\n",
    "# exp42_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp42_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp42_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp42_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp42_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp42_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp42_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp42_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp42_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_columns = [\"#object_id\", \"description\", \"result_timestamp\", \"lamax\", \"laeq\"]\n",
    "# naamse35_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';', usecols=noise_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - January\n",
    "# naamse35_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - February\n",
    "# naamse35_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - March\n",
    "# naamse35_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - April\n",
    "# naamse35_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - May\n",
    "# naamse35_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - June\n",
    "# naamse35_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - July\n",
    "# naamse35_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - August\n",
    "# naamse35_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - September\n",
    "# naamse35_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - October\n",
    "# naamse35_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - November\n",
    "# naamse35_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - December\n",
    "# naamse35_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining and aggregating the meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine meteo dataset \n",
    "# meteocombined = pd.concat([Q1_2022, Q2_2022, Q3_2022, Q4_2022], axis=0)\n",
    "# meteocombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "# print(meteocombined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate meteo data by day\n",
    "# avg_meteo_combined = meteocombined.groupby(['Year','Month', 'Day']).mean()\n",
    "# avg_meteo_combined = avg_meteo_combined.reset_index()\n",
    "# avg_meteo_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_max_value = avg_meteo_combined['Month'].max()\n",
    "# print(f\"This combined meteo dataset contains the weather data for all {month_max_value} months.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining and aggregating the noise data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for January together\n",
    "# noise_jan_combined = pd.concat([naamse35_jan, naamse57_jan, naamse62_jan, calvarie_jan, park_jan, naamse81_jan, kiosk_jan, vrijt_jan, his_jan], axis=0)\n",
    "# noise_jan_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jan_combined['result_timestamp'] = pd.to_datetime(noise_jan_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jan_combined['result_date'] = noise_jan_combined['result_timestamp'].dt.date\n",
    "# noise_jan_combined['result_month'] = noise_jan_combined['result_timestamp'].dt.month\n",
    "# noise_jan_combined['result_day'] = noise_jan_combined['result_timestamp'].dt.day\n",
    "# noise_jan_combined['result_hour'] = noise_jan_combined['result_timestamp'].dt.hour\n",
    "# noise_jan_combined['result_minute'] = noise_jan_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jan_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_jan_combined = noise_jan_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jan_combined = avg_jan_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jan_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jan_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "# print(avg_jan_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for February together\n",
    "# noise_feb_combined = pd.concat([naamse35_feb, naamse57_feb, naamse62_feb, calvarie_feb, park_feb, naamse81_feb, kiosk_feb, vrijt_feb, his_feb], axis=0)\n",
    "# noise_feb_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_feb_combined['result_timestamp'] = pd.to_datetime(noise_feb_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_feb_combined['result_date'] = noise_feb_combined['result_timestamp'].dt.date\n",
    "# noise_feb_combined['result_month'] = noise_feb_combined['result_timestamp'].dt.month\n",
    "# noise_feb_combined['result_day'] = noise_feb_combined['result_timestamp'].dt.day\n",
    "# noise_feb_combined['result_hour'] = noise_feb_combined['result_timestamp'].dt.hour\n",
    "# noise_feb_combined['result_minute'] = noise_feb_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_feb_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_feb_combined = noise_feb_combined.groupby(['result_date','description']).mean()\n",
    "# avg_feb_combined = avg_feb_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_feb_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_feb_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_feb_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for March together\n",
    "# noise_mar_combined = pd.concat([naamse35_mar, naamse57_mar, naamse62_mar, calvarie_mar, park_mar, naamse81_mar, kiosk_mar, vrijt_mar, his_mar], axis=0)\n",
    "# noise_mar_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_mar_combined['result_timestamp'] = pd.to_datetime(noise_mar_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_mar_combined['result_date'] = noise_mar_combined['result_timestamp'].dt.date\n",
    "# noise_mar_combined['result_month'] = noise_mar_combined['result_timestamp'].dt.month\n",
    "# noise_mar_combined['result_day'] = noise_mar_combined['result_timestamp'].dt.day\n",
    "# noise_mar_combined['result_hour'] = noise_mar_combined['result_timestamp'].dt.hour\n",
    "# noise_mar_combined['result_minute'] = noise_mar_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_mar_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_mar_combined = noise_mar_combined.groupby(['result_date','description']).mean()\n",
    "# avg_mar_combined = avg_mar_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_mar_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_mar_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_mar_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- April "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for April together\n",
    "# noise_apr_combined = pd.concat([naamse35_apr, naamse57_apr, naamse62_apr, calvarie_apr, park_apr, naamse81_apr, kiosk_apr, vrijt_apr, his_apr], axis=0)\n",
    "# noise_apr_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_apr_combined['result_timestamp'] = pd.to_datetime(noise_apr_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_apr_combined['result_date'] = noise_apr_combined['result_timestamp'].dt.date\n",
    "# noise_apr_combined['result_month'] = noise_apr_combined['result_timestamp'].dt.month\n",
    "# noise_apr_combined['result_day'] = noise_apr_combined['result_timestamp'].dt.day\n",
    "# noise_apr_combined['result_hour'] = noise_apr_combined['result_timestamp'].dt.hour\n",
    "# noise_apr_combined['result_minute'] = noise_apr_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_apr_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_apr_combined = noise_apr_combined.groupby(['result_date','description']).mean()\n",
    "# avg_apr_combined = avg_apr_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_apr_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_apr_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_apr_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for May together\n",
    "# noise_may_combined = pd.concat([naamse35_may, naamse57_may, naamse62_may, calvarie_may, park_may, naamse81_may, kiosk_may, vrijt_may, his_may], axis=0)\n",
    "# noise_may_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_may_combined['result_timestamp'] = pd.to_datetime(noise_may_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_may_combined['result_date'] = noise_may_combined['result_timestamp'].dt.date\n",
    "# noise_may_combined['result_month'] = noise_may_combined['result_timestamp'].dt.month\n",
    "# noise_may_combined['result_day'] = noise_may_combined['result_timestamp'].dt.day\n",
    "# noise_may_combined['result_hour'] = noise_may_combined['result_timestamp'].dt.hour\n",
    "# noise_may_combined['result_minute'] = noise_may_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_may_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_may_combined = noise_may_combined.groupby(['result_date','description']).mean()\n",
    "# avg_may_combined = avg_may_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_may_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_may_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_may_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for June together\n",
    "# noise_jun_combined = pd.concat([naamse35_jun, naamse57_jun, naamse62_jun, calvarie_jun, park_jun, naamse81_jun, kiosk_jun, vrijt_jun, his_jun], axis=0)\n",
    "# noise_jun_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jun_combined['result_timestamp'] = pd.to_datetime(noise_jun_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jun_combined['result_date'] = noise_jun_combined['result_timestamp'].dt.date\n",
    "# noise_jun_combined['result_month'] = noise_jun_combined['result_timestamp'].dt.month\n",
    "# noise_jun_combined['result_day'] = noise_jun_combined['result_timestamp'].dt.day\n",
    "# noise_jun_combined['result_hour'] = noise_jun_combined['result_timestamp'].dt.hour\n",
    "# noise_jun_combined['result_minute'] = noise_jun_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jun_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data by day\n",
    "# avg_jun_combined = noise_jun_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jun_combined = avg_jun_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jun_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jun_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_jun_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for July together\n",
    "# noise_jul_combined = pd.concat([naamse35_jul, naamse57_jul, naamse62_jul, calvarie_jul, park_jul, naamse81_jul, kiosk_jul, vrijt_jul, his_jul], axis=0)\n",
    "# noise_jul_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jul_combined['result_timestamp'] = pd.to_datetime(noise_jul_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jul_combined['result_date'] = noise_jul_combined['result_timestamp'].dt.date\n",
    "# noise_jul_combined['result_month'] = noise_jul_combined['result_timestamp'].dt.month\n",
    "# noise_jul_combined['result_day'] = noise_jul_combined['result_timestamp'].dt.day\n",
    "# noise_jul_combined['result_hour'] = noise_jul_combined['result_timestamp'].dt.hour\n",
    "# noise_jul_combined['result_minute'] = noise_jul_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jul_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_jul_combined = noise_jul_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jul_combined = avg_jul_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jul_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jul_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_jul_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for August together\n",
    "# noise_aug_combined = pd.concat([naamse35_aug, naamse57_aug, naamse62_aug, calvarie_aug, park_aug, naamse81_aug, kiosk_aug, vrijt_aug, his_aug], axis=0)\n",
    "# noise_aug_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_aug_combined['result_timestamp'] = pd.to_datetime(noise_aug_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_aug_combined['result_date'] = noise_aug_combined['result_timestamp'].dt.date\n",
    "# noise_aug_combined['result_month'] = noise_aug_combined['result_timestamp'].dt.month\n",
    "# noise_aug_combined['result_day'] = noise_aug_combined['result_timestamp'].dt.day\n",
    "# noise_aug_combined['result_hour'] = noise_aug_combined['result_timestamp'].dt.hour\n",
    "# noise_aug_combined['result_minute'] = noise_aug_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_aug_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_aug_combined = noise_aug_combined.groupby(['result_date','description']).mean()\n",
    "# avg_aug_combined = avg_aug_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_aug_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_aug_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_aug_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for September together\n",
    "# noise_sep_combined = pd.concat([naamse35_sep, naamse57_sep, naamse62_sep, calvarie_sep, park_sep, naamse81_sep, kiosk_sep, vrijt_sep, his_sep], axis=0)\n",
    "# noise_sep_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_sep_combined['result_timestamp'] = pd.to_datetime(noise_sep_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_sep_combined['result_date'] = noise_sep_combined['result_timestamp'].dt.date\n",
    "# noise_sep_combined['result_month'] = noise_sep_combined['result_timestamp'].dt.month\n",
    "# noise_sep_combined['result_day'] = noise_sep_combined['result_timestamp'].dt.day\n",
    "# noise_sep_combined['result_hour'] = noise_sep_combined['result_timestamp'].dt.hour\n",
    "# noise_sep_combined['result_minute'] = noise_sep_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_sep_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_sep_combined = noise_sep_combined.groupby(['result_date','description']).mean()\n",
    "# avg_sep_combined = avg_sep_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_sep_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_sep_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_sep_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for Octber together\n",
    "# noise_oct_combined = pd.concat([naamse35_oct, naamse57_oct, naamse62_oct, calvarie_oct, park_oct, naamse81_oct, kiosk_oct, vrijt_oct, his_oct], axis=0)\n",
    "# noise_oct_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_oct_combined['result_timestamp'] = pd.to_datetime(noise_oct_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_oct_combined['result_date'] = noise_oct_combined['result_timestamp'].dt.date\n",
    "# noise_oct_combined['result_month'] = noise_oct_combined['result_timestamp'].dt.month\n",
    "# noise_oct_combined['result_day'] = noise_oct_combined['result_timestamp'].dt.day\n",
    "# noise_oct_combined['result_hour'] = noise_oct_combined['result_timestamp'].dt.hour\n",
    "# noise_oct_combined['result_minute'] = noise_oct_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_oct_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_oct_combined = noise_oct_combined.groupby(['result_date','description']).mean()\n",
    "# avg_oct_combined = avg_oct_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_oct_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_oct_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_oct_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for November together\n",
    "# noise_nov_combined = pd.concat([naamse35_nov, naamse57_nov, naamse62_nov, calvarie_nov, park_nov, naamse81_nov, kiosk_nov, vrijt_nov, his_nov], axis=0)\n",
    "# noise_nov_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_nov_combined['result_timestamp'] = pd.to_datetime(noise_nov_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_nov_combined['result_date'] = noise_nov_combined['result_timestamp'].dt.date\n",
    "# noise_nov_combined['result_month'] = noise_nov_combined['result_timestamp'].dt.month\n",
    "# noise_nov_combined['result_day'] = noise_nov_combined['result_timestamp'].dt.day\n",
    "# noise_nov_combined['result_hour'] = noise_nov_combined['result_timestamp'].dt.hour\n",
    "# noise_nov_combined['result_minute'] = noise_nov_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_nov_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_nov_combined = noise_nov_combined.groupby(['result_date','description']).mean()\n",
    "# avg_nov_combined = avg_nov_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_nov_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_nov_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_nov_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for December together\n",
    "# noise_dec_combined = pd.concat([naamse35_dec, naamse57_dec, naamse62_dec, calvarie_dec, park_dec, naamse81_dec, kiosk_dec, vrijt_dec, his_dec], axis=0)\n",
    "# noise_dec_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_dec_combined['result_timestamp'] = pd.to_datetime(noise_dec_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_dec_combined['result_date'] = noise_dec_combined['result_timestamp'].dt.date\n",
    "# noise_dec_combined['result_month'] = noise_dec_combined['result_timestamp'].dt.month\n",
    "# noise_dec_combined['result_day'] = noise_dec_combined['result_timestamp'].dt.day\n",
    "# noise_dec_combined['result_hour'] = noise_dec_combined['result_timestamp'].dt.hour\n",
    "# noise_dec_combined['result_minute'] = noise_dec_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_dec_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_dec_combined = noise_dec_combined.groupby(['result_date','description']).mean()\n",
    "# avg_dec_combined = avg_dec_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_dec_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_dec_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_dec_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining monthly noise level datasets into a yearly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the monthly datasets\n",
    "datasets = [avg_jan_combined, avg_feb_combined, avg_mar_combined, avg_apr_combined, avg_may_combined, avg_jun_combined, avg_jul_combined, avg_aug_combined, avg_sep_combined, avg_oct_combined, avg_nov_combined, avg_dec_combined]\n",
    "\n",
    "# Concatenate the datasets vertically\n",
    "avg_year_combined = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Sort the combined dataset by 'result_date' in ascending order\n",
    "avg_year_combined.sort_values(by='result_date', inplace=True)\n",
    "\n",
    "# Reset the index of the combined dataset\n",
    "avg_year_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the combined and sorted yearly dataset\n",
    "avg_year_combined.head(2000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
