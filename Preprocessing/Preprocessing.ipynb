{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading meteo data\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "years = ['2022']\n",
    "base_url_meteo = 'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_{}{}.csv'\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        url = base_url_meteo.format(year, quarter)\n",
    "        df = pd.read_csv(url)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building preprocessing pipeline\n",
    "# Step 1: Concatenate datasets\n",
    "def concatenate_datasets(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 2: Convert UTC to CEST by adding 2 hours\n",
    "def convert_utc_to_cest(df):\n",
    "    df['DATEUTC'] = pd.to_datetime(df['DATEUTC'])\n",
    "    df['DATECEST'] = df['DATEUTC']+ pd.Timedelta(hours=2)\n",
    "    return df\n",
    "\n",
    "# Steo 3: Update the month day hour columns to CEST\n",
    "def convert_time(df):\n",
    "    df['Month'] = df['DATECEST'].dt.month\n",
    "    df['Day'] = df['DATECEST'].dt.day\n",
    "    df['Hour'] = df['DATECEST'].dt.hour\n",
    "    return df\n",
    "\n",
    "# Step 4: Drop columns\n",
    "def drop_columns(df):\n",
    "    columns_to_keep = ['DATECEST', 'LC_RAININ', 'LC_DAILYRAIN', 'LC_WINDDIR', 'LC_WINDSPEED', 'LC_TEMP_QCL3', 'Month', 'Day', 'Hour']  #there's less columns we keep than drop\n",
    "    columns_to_drop = set(df.columns) - set(columns_to_keep)\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 5: Check for percentage of missing values in each column\n",
    "def print_null_percentage(df):\n",
    "    null_percentage = df.isnull().sum() / len(df)\n",
    "    print('The percentage of missing values in each column')\n",
    "    print(null_percentage)\n",
    "    return df\n",
    "\n",
    "# Step 6: Forward fill missing values\n",
    "def forward_fill(df):\n",
    "    return df.ffill()\n",
    "\n",
    "# Step 7: Check whether there are missing values left\n",
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    print('Check whether there are missing values left')\n",
    "    print(missing_values)\n",
    "    return df\n",
    "\n",
    "# Step 8: Calculate summary statistics for daily rain sum\n",
    "def daily_rain_sum(df):\n",
    "    summary_stats = df['LC_DAILYRAIN'].describe()\n",
    "    print('Summary statistics for daily rain sum')\n",
    "    print(summary_stats)\n",
    "    return df\n",
    "\n",
    "# Step 9: Calculate fraction of non-zero values in the 'LC_DAILYRAIN' column\n",
    "def non_zero_fraction(df):\n",
    "    nonzero_count = np.count_nonzero(df['LC_DAILYRAIN'])\n",
    "    non_zero_frac = nonzero_count/len(df)\n",
    "    print(\"Fraction of non-zero values:\", non_zero_frac)\n",
    "    return df\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_meteo = Pipeline([\n",
    "    ('concatenate_datasets', FunctionTransformer(concatenate_datasets)),\n",
    "    ('convert_utc_to_cest', FunctionTransformer(convert_utc_to_cest)),\n",
    "    ('convert_time', FunctionTransformer(convert_time)),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('print_null_percentage', FunctionTransformer(print_null_percentage)),\n",
    "    ('forward_fill', FunctionTransformer(forward_fill)),\n",
    "    ('check_missing_values', FunctionTransformer(check_missing_values)),\n",
    "    ('daily_rain_sum', FunctionTransformer(daily_rain_sum)),\n",
    "    ('non_zero_fraction', FunctionTransformer(non_zero_fraction))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the pipeline and generate hourly, daily, and monthly meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in each column\n",
      "LC_RAININ       0.056770\n",
      "LC_DAILYRAIN    0.056770\n",
      "LC_WINDDIR      0.056770\n",
      "LC_WINDSPEED    0.056770\n",
      "Month           0.000000\n",
      "Day             0.000000\n",
      "Hour            0.000000\n",
      "LC_TEMP_QCL3    0.062285\n",
      "DATECEST        0.000000\n",
      "dtype: float64\n",
      "Check whether there are missing values left\n",
      "LC_RAININ       0\n",
      "LC_DAILYRAIN    0\n",
      "LC_WINDDIR      0\n",
      "LC_WINDSPEED    0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "LC_TEMP_QCL3    0\n",
      "DATECEST        0\n",
      "dtype: int64\n",
      "Summary statistics for daily rain sum\n",
      "count    5.546880e+06\n",
      "mean     1.319783e-03\n",
      "std      6.177559e-03\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.540000e-01\n",
      "Name: LC_DAILYRAIN, dtype: float64\n",
      "Fraction of non-zero values: 0.17391488548517364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "      <th>DATECEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13.048027</td>\n",
       "      <td>2022-01-01 02:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.985849</td>\n",
       "      <td>2022-01-01 02:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.950322</td>\n",
       "      <td>2022-01-01 02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.949550</td>\n",
       "      <td>2022-01-01 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.952268</td>\n",
       "      <td>2022-01-01 02:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED  Month  Day  Hour  \\\n",
       "0        0.0           0.0      -169.0          0.43      1    1     2   \n",
       "1        0.0           0.0      -170.0          0.33      1    1     2   \n",
       "2        0.0           0.0      -167.0          0.46      1    1     2   \n",
       "3        0.0           0.0      -160.0          0.52      1    1     2   \n",
       "4        0.0           0.0      -166.0          0.51      1    1     2   \n",
       "\n",
       "   LC_TEMP_QCL3            DATECEST  \n",
       "0     13.048027 2022-01-01 02:10:00  \n",
       "1     12.985849 2022-01-01 02:20:00  \n",
       "2     12.950322 2022-01-01 02:30:00  \n",
       "3     12.949550 2022-01-01 02:40:00  \n",
       "4     12.952268 2022-01-01 02:50:00  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the pipeline\n",
    "meteo_combined_df = pipeline_meteo.fit_transform(dfs)\n",
    "meteo_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>-33.566358</td>\n",
       "      <td>1.487099</td>\n",
       "      <td>15.513391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>-29.188272</td>\n",
       "      <td>1.465571</td>\n",
       "      <td>15.770757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-18.197324</td>\n",
       "      <td>0.389565</td>\n",
       "      <td>13.100358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16.227891</td>\n",
       "      <td>0.222602</td>\n",
       "      <td>12.669197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.710884</td>\n",
       "      <td>0.217194</td>\n",
       "      <td>12.520271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Day  Hour  LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED  \\\n",
       "0      1    1     0   0.000023      0.002997  -33.566358      1.487099   \n",
       "1      1    1     1   0.000019      0.002174  -29.188272      1.465571   \n",
       "2      1    1     2   0.000003      0.000360  -18.197324      0.389565   \n",
       "3      1    1     3   0.000007      0.000000  -16.227891      0.222602   \n",
       "4      1    1     4   0.000009      0.000000  -13.710884      0.217194   \n",
       "\n",
       "   LC_TEMP_QCL3  \n",
       "0     15.513391  \n",
       "1     15.770757  \n",
       "2     13.100358  \n",
       "3     12.669197  \n",
       "4     12.520271  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per hour\n",
    "\n",
    "# Specify the aggregation function for each column\n",
    "  # for LC_DAILYRAIN we take the last value because it's cumulative, for other columns the mean\n",
    "aggregations = {\n",
    "    'LC_DAILYRAIN': 'mean',  # Select the last value for 'LC_DAILYRAIN' ###TAKE MEAN FOR NOW TO MAKE THE GRAPHS LOOK OK\n",
    "    'LC_RAININ': 'mean',  \n",
    "    'LC_WINDDIR': 'mean',\n",
    "    'LC_WINDDIR': 'mean', \n",
    "    'LC_WINDSPEED': 'mean', \n",
    "    'LC_TEMP_QCL3': 'mean'\n",
    "}\n",
    "\n",
    "# Perform the groupby aggregation\n",
    "meteo_per_hour = meteo_combined_df.groupby(['Month', 'Day', 'Hour']).mean()\n",
    "meteo_per_hour = meteo_per_hour.reset_index()\n",
    "meteo_per_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>-7.446286</td>\n",
       "      <td>0.414860</td>\n",
       "      <td>11.400646</td>\n",
       "      <td>12.524393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>-25.975694</td>\n",
       "      <td>0.649436</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>12.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>-37.386338</td>\n",
       "      <td>0.711017</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>9.769569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>-23.273101</td>\n",
       "      <td>0.344787</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>7.158320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>-44.453160</td>\n",
       "      <td>0.603273</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>3.790048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Day  LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED       Hour  \\\n",
       "0      1    1   0.000004      0.000275   -7.446286      0.414860  11.400646   \n",
       "1      1    2   0.000654      0.002608  -25.975694      0.649436  11.500000   \n",
       "2      1    3   0.000675      0.006600  -37.386338      0.711017  11.500000   \n",
       "3      1    4   0.000506      0.003867  -23.273101      0.344787  11.500000   \n",
       "4      1    5   0.000089      0.000738  -44.453160      0.603273  11.500000   \n",
       "\n",
       "   LC_TEMP_QCL3  \n",
       "0     12.524393  \n",
       "1     12.004777  \n",
       "2      9.769569  \n",
       "3      7.158320  \n",
       "4      3.790048  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per day\n",
    "\n",
    "# still the same \"aggregations\" as before\n",
    "meteo_per_day = meteo_combined_df.groupby(['Month', 'Day']).mean()\n",
    "meteo_per_day = meteo_per_day.reset_index()\n",
    "meteo_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>-16.307700</td>\n",
       "      <td>0.339932</td>\n",
       "      <td>15.995544</td>\n",
       "      <td>11.496766</td>\n",
       "      <td>4.733596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>-25.317653</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>6.929743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>12.215986</td>\n",
       "      <td>0.250748</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>8.108503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>3.631846</td>\n",
       "      <td>0.369361</td>\n",
       "      <td>15.504041</td>\n",
       "      <td>11.503034</td>\n",
       "      <td>10.690818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>-9.013140</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>15.568973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED        Day  \\\n",
       "0      1   0.000112      0.001034  -16.307700      0.339932  15.995544   \n",
       "1      2   0.000131      0.001263  -25.317653      0.741510  14.500000   \n",
       "2      3   0.000010      0.000104   12.215986      0.250748  16.000000   \n",
       "3      4   0.000054      0.000504    3.631846      0.369361  15.504041   \n",
       "4      5   0.000076      0.000653   -9.013140      0.240605  16.000000   \n",
       "\n",
       "        Hour  LC_TEMP_QCL3  \n",
       "0  11.496766      4.733596  \n",
       "1  11.500000      6.929743  \n",
       "2  11.500000      8.108503  \n",
       "3  11.503034     10.690818  \n",
       "4  11.500000     15.568973  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe per month\n",
    "\n",
    "# still the same \"aggregations\" as before\n",
    "meteo_per_month = meteo_combined_df.groupby(['Month']).mean()\n",
    "meteo_per_month = meteo_per_month.reset_index()\n",
    "meteo_per_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# export dataframes (only needs to be ran once so comment it out)\n",
    "meteo_per_hour.to_csv('hourly_weatherdata_2022.csv', index=False)\n",
    "meteo_per_day.to_csv('daily_weatherdata_2022.csv', index=False)\n",
    "meteo_per_month.to_csv('monthly_weatherdata_2022.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dfs to reduce memory use\n",
    "del dfs\n",
    "del meteo_combined_df\n",
    "del meteo_per_hour\n",
    "del meteo_per_day\n",
    "del meteo_per_month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise level data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- January "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs\n",
    "urls_jan = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_jan = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_jan in urls_jan:\n",
    "    df_jan = pd.read_csv(url_jan, header=0, sep=';')\n",
    "    dfs_jan.append(df_jan)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL called dfs_jan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_feb = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_feb = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_feb in urls_feb:\n",
    "    df_feb = pd.read_csv(url_feb, header=0, sep=';')\n",
    "    dfs_feb.append(df_feb)\n",
    "\n",
    "# Now we have a list of DataFrames for each URL called dfs_feb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_mar = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_mar = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_mar in urls_mar:\n",
    "    df_mar = pd.read_csv(url_mar, header=0, sep=';')\n",
    "    dfs_mar.append(df_mar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_apr = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_apr = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_apr in urls_apr:\n",
    "    df_apr = pd.read_csv(url_apr, header=0, sep=';')\n",
    "    dfs_apr.append(df_apr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_may = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_may = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_may in urls_may:\n",
    "    df_may = pd.read_csv(url_may, header=0, sep=';')\n",
    "    dfs_may.append(df_may)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "url_jun = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_jun = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_jun in url_jun:\n",
    "    df_jun = pd.read_csv(url_jun, header=0, sep=';')\n",
    "    dfs_jun.append(df_jun)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_jul = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_jul = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_jul in urls_jul:\n",
    "    df_jul = pd.read_csv(url_jul, header=0, sep=';')\n",
    "    dfs_jul.append(df_jul)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_aug = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_aug = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_aug in urls_aug:\n",
    "    df_aug = pd.read_csv(url_aug, header=0, sep=';')\n",
    "    dfs_aug.append(df_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_sep = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_sep = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_sep in urls_sep:\n",
    "    df_sep = pd.read_csv(url_sep, header=0, sep=';')\n",
    "    dfs_sep.append(df_sep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_oct = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_oct = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_oct in urls_oct:\n",
    "    df_oct = pd.read_csv(url_oct, header=0, sep=';')\n",
    "    dfs_oct.append(df_oct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_nov = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_nov = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_nov in urls_nov:\n",
    "    df_nov = pd.read_csv(url_nov, header=0, sep=';')\n",
    "    dfs_nov.append(df_nov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of URLs \n",
    "urls_dec = [\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255439_mp-01-naamsestraat-35-maxim.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255440_mp-02-naamsestraat-57-xior.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255441_mp-03-naamsestraat-62-taste.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255442_mp-05-calvariekapel-ku-leuven.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255443_mp-06-parkstraat-2-la-filosovia.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255444_mp-07-naamsestraat-81.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255445_mp-08-kiosk-stadspark.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_280324_mp08bis---vrijthof.csv',\n",
    "    'https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_303910_mp-04-his-hears.csv'\n",
    "   ]\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs_dec = []\n",
    "\n",
    "# Loop through each URL and read the CSV into a DataFrame\n",
    "for url_dec in urls_dec:\n",
    "    df_dec = pd.read_csv(url_dec, header=0, sep=';')\n",
    "    dfs_dec.append(df_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets\n",
    "dfs_2022 = [dfs_jan,dfs_feb,dfs_mar,dfs_apr,dfs_may,dfs_jun,dfs_jul,dfs_aug,dfs_sep,dfs_oct,dfs_nov,dfs_dec]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for modelling purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A pipeline to generate data for modelling purpose\n",
    "# Step 1: Concatenate datasets\n",
    "def concatenate_datasets(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 2: Convert timestamps to datetime\n",
    "def convert_to_datetime(df):\n",
    "    df['result_timestamp'] = pd.to_datetime(df['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "    return df\n",
    "\n",
    "# Step 3: Extract month, day, hour, minute from timestamps\n",
    "def extract_time(df):\n",
    "    df['month'] = df['result_timestamp'].dt.month\n",
    "    df['day'] = df['result_timestamp'].dt.day\n",
    "    df['hour'] = df['result_timestamp'].dt.hour\n",
    "    #   df['minute'] = df['result_timestamp'].dt.minute\n",
    "    return df\n",
    "\n",
    "# Step 4: Drop columns\n",
    "def drop_columns(df):\n",
    "    columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "    columns_to_drop = set(df.columns) - set(columns_to_keep)\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_modelling = Pipeline([\n",
    "    ('concatenate_datasets', FunctionTransformer(concatenate_datasets)),\n",
    "    ('convert_to_datetime', FunctionTransformer(convert_to_datetime)),\n",
    "    ('extract_time', FunctionTransformer(extract_time)),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pipeline to get modelling dataset\n",
    "transformed_modelling_datasets = []\n",
    "for df_2022 in dfs_2022:\n",
    "    transformed_modelling_dataset = pipeline_modelling.fit_transform(df_2022)\n",
    "    transformed_modelling_datasets.append(transformed_modelling_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_modelling = pd.concat(transformed_modelling_datasets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_modelling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/srd4ffps1qz5k88lkjbdywqw0000gn/T/ipykernel_42718/2473566293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_modelling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_modelling' is not defined"
     ]
    }
   ],
   "source": [
    "data_modelling.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description       0\n",
      "lamax          1454\n",
      "laeq             87\n",
      "month             0\n",
      "day               0\n",
      "hour              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data_modelling.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting file (only needs to be run one time so comment it out)\n",
    "data_modelling.to_csv('noise_for_modelling.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete for memory reduce\n",
    "del data_modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For visualization purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build pipleines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall dataset preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate datasets\n",
    "def concatenate_datasets(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 2: Convert timestamps to datetime\n",
    "def convert_to_datetime(df):\n",
    "    df['result_timestamp'] = pd.to_datetime(df['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "    return df\n",
    "\n",
    "# Step 3: Extract month, day, hour, minute from timestamps\n",
    "def extract_time(df):\n",
    "    df['month'] = df['result_timestamp'].dt.month\n",
    "    df['day'] = df['result_timestamp'].dt.day\n",
    "    df['hour'] = df['result_timestamp'].dt.hour\n",
    "    #   df['minute'] = df['result_timestamp'].dt.minute\n",
    "    return df\n",
    "\n",
    "# Step 4: Drop columns\n",
    "def drop_columns(df):\n",
    "    columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "    columns_to_drop = set(df.columns) - set(columns_to_keep)\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 5: Forward fill missing values\n",
    "def forward_fill(df):\n",
    "    return df.ffill()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_general = Pipeline([\n",
    "    ('concatenate_datasets', FunctionTransformer(concatenate_datasets)),\n",
    "    ('convert_to_datetime', FunctionTransformer(convert_to_datetime)),\n",
    "    ('extract_time', FunctionTransformer(extract_time)),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('forward_fill', FunctionTransformer(forward_fill))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conintue to get hourly, daily, and monthly aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hourly pipeline\n",
    "# Step 6: Perform groupby to create dataframe per hour\n",
    "def perform_groupby(df):\n",
    "    return df.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "\n",
    "# Step 7: Reset index\n",
    "def reset_index_func(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "# Step 8: Standardize the data\n",
    "def standardize_columns(df, columns_to_standardize):\n",
    "    scaler = StandardScaler()\n",
    "    standardized_values = scaler.fit_transform(df[columns_to_standardize])\n",
    "    new_columns = [column + '_standardized' for column in columns_to_standardize]\n",
    "    df[new_columns] = pd.DataFrame(standardized_values, columns=new_columns)\n",
    "    return df\n",
    "\n",
    "# Step 9: Define a custom transformer to create the new column\n",
    "class DateTransformer:\n",
    "    def transform(self, df):\n",
    "        df['year'] = 2022\n",
    "        df['date'] = df.apply(lambda row: pd.to_datetime(f\"{int(row['day']):02d}-{int(row['month']):02d}-{int(row['year']):04d}-{int(row['hour']):02d}\", format='%d-%m-%Y-%H'), axis=1)\n",
    "        df['date'] = df['date'].dt.strftime('%H:%M %d-%m-%Y')\n",
    "        return df\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "# Step 10: Drop the year column\n",
    "def drop_year_column(df):\n",
    "    return df.drop(columns='year')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_hourly = Pipeline([\n",
    "    ('groupby', FunctionTransformer(perform_groupby)),\n",
    "    ('reset_index', FunctionTransformer(reset_index_func)),\n",
    "    ('standardize_columns', FunctionTransformer(standardize_columns, kw_args={'columns_to_standardize': ['lamax', 'laeq']})),\n",
    "      ('date_transformer', DateTransformer()),\n",
    "    ('drop_year_column', FunctionTransformer(drop_year_column))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Daily pipeline\n",
    "# Step 6: Perform groupby to create dataframe per hour\n",
    "def perform_groupby(df):\n",
    "    return df.groupby(['month', 'day', 'description']).mean()\n",
    "\n",
    "# Step 7: Reset index\n",
    "def reset_index_func(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "# Step 8: Standardize the data\n",
    "def standardize_columns(df, columns_to_standardize):\n",
    "    scaler = StandardScaler()\n",
    "    standardized_values = scaler.fit_transform(df[columns_to_standardize])\n",
    "    new_columns = [column + '_standardized' for column in columns_to_standardize]\n",
    "    df[new_columns] = pd.DataFrame(standardized_values, columns=new_columns)\n",
    "    return df\n",
    "\n",
    "# Step 9: Drop unwanted columns\n",
    "def drop_columns(df):\n",
    "    return df.drop(columns='hour')\n",
    "\n",
    "# Step 10: Define a custom transformer to create the new column\n",
    "class DateTransformer:\n",
    "    def transform(self, df):\n",
    "        df['year'] = 2022\n",
    "        df['date'] = df.apply(lambda row: pd.to_datetime(f\"{int(row['day']):02d}-{int(row['month']):02d}-{int(row['year']):04d}\", format='%d-%m-%Y'), axis=1)\n",
    "        df['date'] = df['date'].dt.strftime('%d-%m-%Y')\n",
    "        return df\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "# Step 11: Drop the year column\n",
    "def drop_year_column(df):\n",
    "    return df.drop(columns='year')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_daily = Pipeline([\n",
    "    ('groupby', FunctionTransformer(perform_groupby)),\n",
    "    ('reset_index', FunctionTransformer(reset_index_func)),\n",
    "    ('standardize_columns', FunctionTransformer(standardize_columns, kw_args={'columns_to_standardize': ['lamax', 'laeq']})),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('date_transformer', DateTransformer()),\n",
    "    ('drop_year_column', FunctionTransformer(drop_year_column))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monthly pipeline\n",
    "# Step 6: Perform groupby to create dataframe per hour\n",
    "def perform_groupby(df):\n",
    "    return df.groupby(['month', 'description']).mean()\n",
    "\n",
    "# Step 7: Reset index\n",
    "def reset_index_func(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "# Step 8: Standardize the data\n",
    "def standardize_columns(df, columns_to_standardize):\n",
    "    scaler = StandardScaler()\n",
    "    standardized_values = scaler.fit_transform(df[columns_to_standardize])\n",
    "    new_columns = [column + '_standardized' for column in columns_to_standardize]\n",
    "    df[new_columns] = pd.DataFrame(standardized_values, columns=new_columns)\n",
    "    return df\n",
    "\n",
    "# Step 9: Drop unwanted columns\n",
    "def drop_columns(df):\n",
    "    columns_to_drop = ['day', 'hour']\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 10: Define a custom transformer to create the new column\n",
    "class DateTransformer:\n",
    "    def transform(self, df):\n",
    "        df['year'] = 2022\n",
    "        df['date'] = df.apply(lambda row: pd.to_datetime(f\"{int(row['month']):02d}-{int(row['year']):04d}\", format='%m-%Y'), axis=1)\n",
    "        df['date'] = df['date'].dt.strftime('%b %Y')\n",
    "        return df\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "# Step 11: Drop the year column\n",
    "def drop_year_column(df):\n",
    "    return df.drop(columns='year')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_monthly = Pipeline([\n",
    "    ('groupby', FunctionTransformer(perform_groupby)),\n",
    "    ('reset_index', FunctionTransformer(reset_index_func)),\n",
    "    ('standardize_columns', FunctionTransformer(standardize_columns, kw_args={'columns_to_standardize': ['lamax', 'laeq']})),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('date_transformer', DateTransformer()),\n",
    "    ('drop_year_column', FunctionTransformer(drop_year_column))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pipeline to the overall dataset\n",
    "transformed_overall_datasets = []\n",
    "for df_2022 in dfs_2022:\n",
    "    transformed_overall_dataset = pipeline_general.fit_transform(df_2022)\n",
    "    transformed_overall_datasets.append(transformed_overall_dataset)\n",
    "\n",
    "combined = pd.concat(transformed_overall_datasets, ignore_index=True)\n",
    "combined.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pipeline to the combined and collect hourly data\n",
    "combined_hourly = pipeline_hourly.fit_transform(combined)\n",
    "\n",
    "combined_hourly.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pipeline to the combined and collect daily data\n",
    "combined_daily = pipeline_daily.fit_transform(combined)\n",
    "\n",
    "combined_daily.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pipeline to the combined and collect monthly data\n",
    "combined_monthly = pipeline_monthly.fit_transform(combined)\n",
    "\n",
    "combined_monthly.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether there are missing values left\n",
    "print(combined_hourly.isnull().sum())\n",
    "print(combined_daily.isnull().sum())\n",
    "print(combined_monthly.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# exporting file (only needs to be run one time so comment it out)\n",
    "combined_hourly.to_csv('hourly_noisedata_2022.csv', index=False)  \n",
    "combined_daily.to_csv('daily_noisedata_2022.csv', index=False) \n",
    "combined_monthly.to_csv('monthly_noisedata_2022.csv', index=False) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Delete the separate dataframes to minimize memory usage\n",
    "del combined_hourly\n",
    "del combined_daily\n",
    "del combined_monthly\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the events data\n",
    "event_mp01 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255439_mp-01-naamsestraat-35-maxim.csv',delimiter=';')\n",
    "event_mp02 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255440_mp-02-naamsestraat-57-xior.csv',delimiter=';')\n",
    "event_mp03 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255441_mp-03-naamsestraat-62-taste.csv',delimiter=';')\n",
    "event_mp04 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_303910_mp-04-his-hears.csv',delimiter=';')\n",
    "event_mp05 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255442_mp-05-calvariekapel-ku-leuven.csv',delimiter=';')\n",
    "event_mp06 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255443_mp-06-parkstraat-2-la-filosovia.csv',delimiter=';')\n",
    "event_mp07 = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255444_mp-07-naamsestraat-81.csv',delimiter=';')\n",
    "#event_mp08stadspark = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_255445_mp-08-kiosk-stadspark.csv',delimiter=';')\n",
    "event_mp08Vrijthof = pd.read_csv('/Users/tianying/Documents/Statistics and Data Science/Course/Modern Data Analytics/MDA project/MDA-Georgia/Data/csv_results_41_280324_mp08bis---vrijthof.csv',delimiter=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess events data for merging purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate data\n",
    "def concatenate_datasets(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 2: Drop columns\n",
    "def drop_columns(df):\n",
    "    columns_to_keep = ['description', 'result_timestamp', 'noise_event_laeq_primary_detected_certainty', 'noise_event_laeq_primary_detected_class']\n",
    "    columns_to_drop = set(df.columns) - set(columns_to_keep)\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 3: Add a column of certainty in percentage form (in string form) \n",
    "def percentage_column(df):\n",
    "    df['certainty_percentage'] = df['noise_event_laeq_primary_detected_certainty'].apply(lambda x: f\"{x}%\" if not pd.isnull(x) else np.nan)\n",
    "    return df\n",
    "\n",
    "# Step 4: extract time from 'result_timestamp' \n",
    "def extract_time(df):\n",
    "    df['result_timestamp'] = pd.to_datetime(df['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "    df['month'] = df['result_timestamp'].dt.month\n",
    "    df['day'] = df['result_timestamp'].dt.day\n",
    "    df['hour'] = df['result_timestamp'].dt.hour\n",
    "    df['minute'] = df['result_timestamp'].dt.minute\n",
    "    df['second'] = df['result_timestamp'].dt.second\n",
    "    df['milliseconds'] = df['result_timestamp'].dt.microsecond // 1000\n",
    "    return df\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_merge_event = Pipeline([\n",
    "    ('concatenate_datasets', FunctionTransformer(concatenate_datasets)),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('percentage_column', FunctionTransformer(percentage_column)),\n",
    "    ('extract_time', FunctionTransformer(extract_time))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the events data\n",
    "events = [event_mp01,event_mp02,event_mp03,event_mp04,event_mp05,event_mp06,event_mp07,event_mp08Vrijthof] #mp08stadspark is not used in noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 08:27:21.737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 13:58:21.356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 16:43:15.393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 19:22:48.428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 20:32:20.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81051</th>\n",
       "      <td>MP08bis - Vrijthof</td>\n",
       "      <td>2022-12-29 09:08:11.171</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81052</th>\n",
       "      <td>MP08bis - Vrijthof</td>\n",
       "      <td>2022-12-30 13:54:27.224</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Nature elements - Wind</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81053</th>\n",
       "      <td>MP08bis - Vrijthof</td>\n",
       "      <td>2022-12-30 13:56:57.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81054</th>\n",
       "      <td>MP08bis - Vrijthof</td>\n",
       "      <td>2022-12-30 15:09:33.233</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Nature elements - Wind</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81055</th>\n",
       "      <td>MP08bis - Vrijthof</td>\n",
       "      <td>2022-12-31 12:01:26.480</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Nature elements - Wind</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81056 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         description        result_timestamp  \\\n",
       "0      MP 01: Naamsestraat 35  Maxim 2022-02-28 08:27:21.737   \n",
       "1      MP 01: Naamsestraat 35  Maxim 2022-02-28 13:58:21.356   \n",
       "2      MP 01: Naamsestraat 35  Maxim 2022-02-28 16:43:15.393   \n",
       "3      MP 01: Naamsestraat 35  Maxim 2022-02-28 19:22:48.428   \n",
       "4      MP 01: Naamsestraat 35  Maxim 2022-02-28 20:32:20.440   \n",
       "...                              ...                     ...   \n",
       "81051             MP08bis - Vrijthof 2022-12-29 09:08:11.171   \n",
       "81052             MP08bis - Vrijthof 2022-12-30 13:54:27.224   \n",
       "81053             MP08bis - Vrijthof 2022-12-30 13:56:57.225   \n",
       "81054             MP08bis - Vrijthof 2022-12-30 15:09:33.233   \n",
       "81055             MP08bis - Vrijthof 2022-12-31 12:01:26.480   \n",
       "\n",
       "       noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "...                                            ...   \n",
       "81051                                         99.0   \n",
       "81052                                         99.0   \n",
       "81053                                          0.0   \n",
       "81054                                        100.0   \n",
       "81055                                        100.0   \n",
       "\n",
       "      noise_event_laeq_primary_detected_class certainty_percentage  month  \\\n",
       "0                                         NaN                  NaN      2   \n",
       "1                                         NaN                  NaN      2   \n",
       "2                                         NaN                  NaN      2   \n",
       "3                                         NaN                  NaN      2   \n",
       "4                                         NaN                  NaN      2   \n",
       "...                                       ...                  ...    ...   \n",
       "81051                  Human voice - Shouting                99.0%     12   \n",
       "81052                  Nature elements - Wind                99.0%     12   \n",
       "81053                             Unsupported                 0.0%     12   \n",
       "81054                  Nature elements - Wind               100.0%     12   \n",
       "81055                  Nature elements - Wind               100.0%     12   \n",
       "\n",
       "       day  hour  minute  second  milliseconds  \n",
       "0       28     8      27      21           737  \n",
       "1       28    13      58      21           356  \n",
       "2       28    16      43      15           393  \n",
       "3       28    19      22      48           428  \n",
       "4       28    20      32      20           440  \n",
       "...    ...   ...     ...     ...           ...  \n",
       "81051   29     9       8      11           171  \n",
       "81052   30    13      54      27           224  \n",
       "81053   30    13      56      57           225  \n",
       "81054   30    15       9      33           233  \n",
       "81055   31    12       1      26           480  \n",
       "\n",
       "[81056 rows x 11 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the pipeline\n",
    "combined_event = pipeline_merge_event.fit_transform(events)\n",
    "combined_event.head(1000000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess noise data for merging purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline on noise data for merging purpose\n",
    "# Step 1: Convert timestamps to datetime\n",
    "def convert_to_datetime(df):\n",
    "    df['result_timestamp'] = pd.to_datetime(df['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "    return df\n",
    "\n",
    "# Step 2: Extract month, day, hour, minute from timestamps\n",
    "def extract_time(df):\n",
    "    df['month'] = df['result_timestamp'].dt.month\n",
    "    df['day'] = df['result_timestamp'].dt.day\n",
    "    df['hour'] = df['result_timestamp'].dt.hour\n",
    "    df['minute'] = df['result_timestamp'].dt.minute\n",
    "    df['second'] = df['result_timestamp'].dt.second\n",
    "    df['milliseconds'] = df['result_timestamp'].dt.microsecond // 1000\n",
    "    return df\n",
    "\n",
    "# Step 3: Drop columns\n",
    "def drop_columns(df):\n",
    "    columns_to_keep = ['description', 'lamax', 'laeq', 'month','day','hour','minute','second','milliseconds']\n",
    "    columns_to_drop = set(df.columns) - set(columns_to_keep)\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 4: Forward fill missing values\n",
    "def forward_fill(df):\n",
    "    return df.ffill()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_merge_noise = Pipeline([\n",
    "    ('convert_to_datetime', FunctionTransformer(convert_to_datetime)),\n",
    "    ('extract_time', FunctionTransformer(extract_time)),\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('forward_fill', FunctionTransformer(forward_fill))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the pipeline and merge data month by month (to avoid the crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_columns = ['description','month','day','hour','minute','second','milliseconds']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "jan = pd.concat(dfs_jan, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "jan = pipeline_merge_noise.fit_transform(jan) # Apply pipeline to noise data\n",
    "event_jan = combined_event[combined_event['month'] == 1] # Select event data from corresponding month\n",
    "merged_event_jan = pd.merge(event_jan, jan, on=merge_columns,  how='left') # Merge the event and noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_jan.head()\n",
    "#merged_event_jan.to_csv('merged_event_jan.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del jan\n",
    "del event_jan\n",
    "del merged_event_jan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "feb = pd.concat(dfs_feb, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 08:27:21.737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>737</td>\n",
       "      <td>69.4</td>\n",
       "      <td>68.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 13:58:21.356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>356</td>\n",
       "      <td>73.8</td>\n",
       "      <td>72.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 16:43:15.393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>393</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 19:22:48.428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>428</td>\n",
       "      <td>91.6</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-02-28 20:32:20.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>440</td>\n",
       "      <td>71.9</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-02-28 08:27:21.737   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-02-28 13:58:21.356   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-02-28 16:43:15.393   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-02-28 19:22:48.428   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-02-28 20:32:20.440   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                                     NaN                  NaN      2   28   \n",
       "1                                     NaN                  NaN      2   28   \n",
       "2                                     NaN                  NaN      2   28   \n",
       "3                                     NaN                  NaN      2   28   \n",
       "4                                     NaN                  NaN      2   28   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     8      27      21           737   69.4  68.1  \n",
       "1    13      58      21           356   73.8  72.9  \n",
       "2    16      43      15           393   71.0  70.1  \n",
       "3    19      22      48           428   91.6  87.5  \n",
       "4    20      32      20           440   71.9  69.8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "feb = pipeline_merge_noise.fit_transform(feb) # Apply pipeline to noise data\n",
    "event_feb = combined_event[combined_event['month'] == 2] # Select event data from corresponding month\n",
    "merged_event_feb = pd.merge(event_feb, feb, on=merge_columns,  how='left') # Merge the event and noise data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_feb.head()\n",
    "#merged_event_feb.to_csv('merged_event_feb.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del feb\n",
    "del event_feb\n",
    "del merged_event_feb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "mar = pd.concat(dfs_mar, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "mar_ = pipeline_merge_noise.fit_transform(mar) # Apply pipeline to noise data\n",
    "event_mar = combined_event[combined_event['month'] == 3] # Select event data from corresponding month\n",
    "merged_event_mar = pd.merge(event_mar, mar_, on=merge_columns,  how='left') # Merge the event and noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:07:59.463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>463</td>\n",
       "      <td>74.1</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 01:24:17.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>470</td>\n",
       "      <td>82.1</td>\n",
       "      <td>78.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 01:33:16.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>470</td>\n",
       "      <td>82.4</td>\n",
       "      <td>78.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 02:31:01.476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 03:45:02.482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "      <td>74.8</td>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:07:59.463   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-03-01 01:24:17.470   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-03-01 01:33:16.470   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-03-01 02:31:01.476   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-03-01 03:45:02.482   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                                     NaN                  NaN      3    1   \n",
       "1                                     NaN                  NaN      3    1   \n",
       "2                                     NaN                  NaN      3    1   \n",
       "3                                     NaN                  NaN      3    1   \n",
       "4                                     NaN                  NaN      3    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0       7      59           463   74.1  70.8  \n",
       "1     1      24      17           470   82.1  78.7  \n",
       "2     1      33      16           470   82.4  78.8  \n",
       "3     2      31       1           476    NaN   NaN  \n",
       "4     3      45       2           482   74.8  72.6  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_event_mar.head()\n",
    "#merged_event_mar.to_csv('merged_event_mar.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del mar\n",
    "del event_mar\n",
    "del merged_event_mar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "apr = pd.concat(dfs_apr, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:24:52.570</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>97.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:32:15.550</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Transport road - Siren</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>550</td>\n",
       "      <td>68.8</td>\n",
       "      <td>67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:43:03.570</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>98.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>570</td>\n",
       "      <td>79.8</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:49:51.570</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>570</td>\n",
       "      <td>72.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:57:07.590</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:24:52.570   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:32:15.550   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:43:03.570   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:49:51.570   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:57:07.590   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                         97.0   \n",
       "1                                         78.0   \n",
       "2                                         98.0   \n",
       "3                                        100.0   \n",
       "4                                        100.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                  Human voice - Shouting                97.0%      4    1   \n",
       "1                  Transport road - Siren                78.0%      4    1   \n",
       "2                  Human voice - Shouting                98.0%      4    1   \n",
       "3                  Human voice - Shouting               100.0%      4    1   \n",
       "4                  Human voice - Shouting               100.0%      4    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0      24      52           570    NaN   NaN  \n",
       "1     0      32      15           550   68.8  67.1  \n",
       "2     0      43       3           570   79.8  74.9  \n",
       "3     0      49      51           570   72.5  70.0  \n",
       "4     0      57       7           590    NaN   NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "apr_ = pipeline_merge_noise.fit_transform(apr) # Apply pipeline to noise data\n",
    "event_apr = combined_event[combined_event['month'] == 4] # Select event data from corresponding month\n",
    "merged_event_apr = pd.merge(event_apr, apr_, on=merge_columns,  how='left') # Merge the event and noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_apr.head()\n",
    "#merged_event_apr.to_csv('merged_event_apr.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del apr\n",
    "del event_apr\n",
    "del merged_event_apr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "may = pd.concat(dfs_may, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-05-01 01:14:38.441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-05-01 03:52:50.467</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>97.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>467</td>\n",
       "      <td>71.4</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-05-01 08:23:25.636</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>98.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>636</td>\n",
       "      <td>70.4</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-05-01 09:33:58.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>648</td>\n",
       "      <td>72.7</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-05-01 13:04:54.694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>694</td>\n",
       "      <td>69.7</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-05-01 01:14:38.441   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-05-01 03:52:50.467   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-05-01 08:23:25.636   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-05-01 09:33:58.648   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-05-01 13:04:54.694   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                          0.0   \n",
       "1                                         97.0   \n",
       "2                                         98.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                             Unsupported                 0.0%      5    1   \n",
       "1          Transport road - Passenger car                97.0%      5    1   \n",
       "2          Transport road - Passenger car                98.0%      5    1   \n",
       "3                             Unsupported                 0.0%      5    1   \n",
       "4                             Unsupported                 0.0%      5    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     1      14      38           441    NaN   NaN  \n",
       "1     3      52      50           467   71.4  68.2  \n",
       "2     8      23      25           636   70.4  69.2  \n",
       "3     9      33      58           648   72.7  71.0  \n",
       "4    13       4      54           694   69.7  68.6  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "may_ = pipeline_merge_noise.fit_transform(may) # Apply pipeline to noise data\n",
    "event_may = combined_event[combined_event['month'] == 5] # Select event data from corresponding month\n",
    "merged_event_may = pd.merge(event_may, may_, on=merge_columns,  how='left') # Merge the event and noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_may.head()\n",
    "#merged_event_may.to_csv('merged_event_may.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del may\n",
    "del event_may\n",
    "del merged_event_may"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "jun = pd.concat(dfs_jun, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-06-01 00:03:43.915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>915</td>\n",
       "      <td>65.5</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-06-01 00:34:04.922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-06-01 01:23:42.931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-06-01 01:45:27.935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>935</td>\n",
       "      <td>77.5</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-06-01 01:46:02.935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>935</td>\n",
       "      <td>69.5</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-06-01 00:03:43.915   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-06-01 00:34:04.922   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-06-01 01:23:42.931   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-06-01 01:45:27.935   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-06-01 01:46:02.935   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                                     NaN                  NaN      6    1   \n",
       "1                                     NaN                  NaN      6    1   \n",
       "2                                     NaN                  NaN      6    1   \n",
       "3                                     NaN                  NaN      6    1   \n",
       "4                                     NaN                  NaN      6    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0       3      43           915   65.5  64.7  \n",
       "1     0      34       4           922    NaN   NaN  \n",
       "2     1      23      42           931    NaN   NaN  \n",
       "3     1      45      27           935   77.5  75.2  \n",
       "4     1      46       2           935   69.5  65.8  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "jun_ = pipeline_merge_noise.fit_transform(jun)\n",
    "event_jun = combined_event[combined_event['month'] == 6]\n",
    "merged_event_jun = pd.merge(event_jun, jun_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_jun.head()\n",
    "#merged_event_jun.to_csv('merged_event_jun.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del jun\n",
    "del event_jun\n",
    "del merged_event_jun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "jul = pd.concat(dfs_jul, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-07-01 00:23:46.162</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>75.5</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-07-01 00:45:47.166</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-07-01 00:54:58.168</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>168</td>\n",
       "      <td>64.8</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-07-01 01:16:09.174</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-07-01 01:54:53.183</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>183</td>\n",
       "      <td>66.1</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-07-01 00:23:46.162   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-07-01 00:45:47.166   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-07-01 00:54:58.168   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-07-01 01:16:09.174   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-07-01 01:54:53.183   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                         76.0   \n",
       "1                                         99.0   \n",
       "2                                         99.0   \n",
       "3                                        100.0   \n",
       "4                                        100.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0          Transport road - Passenger car                76.0%      7    1   \n",
       "1          Transport road - Passenger car                99.0%      7    1   \n",
       "2          Transport road - Passenger car                99.0%      7    1   \n",
       "3          Transport road - Passenger car               100.0%      7    1   \n",
       "4          Transport road - Passenger car               100.0%      7    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0      23      46           162   75.5  69.3  \n",
       "1     0      45      47           166    NaN   NaN  \n",
       "2     0      54      58           168   64.8  64.0  \n",
       "3     1      16       9           174    NaN   NaN  \n",
       "4     1      54      53           183   66.1  65.4  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "jul_ = pipeline_merge_noise.fit_transform(jul)\n",
    "event_jul = combined_event[combined_event['month'] == 7]\n",
    "merged_event_jul = pd.merge(event_jul, jul_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_jul.head()\n",
    "#merged_event_jul.to_csv('merged_event_jul.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del jul\n",
    "del event_jul\n",
    "del merged_event_jul"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "aug = pd.concat(dfs_aug, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-08-01 00:46:10.988</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>988</td>\n",
       "      <td>66.6</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-08-01 00:51:07.989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-08-01 00:54:51.990</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-08-01 01:25:17.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>65.1</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-08-01 01:32:56.200</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>93.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>200</td>\n",
       "      <td>73.6</td>\n",
       "      <td>71.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-08-01 00:46:10.988   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-08-01 00:51:07.989   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-08-01 00:54:51.990   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-08-01 01:25:17.000   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-08-01 01:32:56.200   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                        100.0   \n",
       "1                                          0.0   \n",
       "2                                         99.0   \n",
       "3                                        100.0   \n",
       "4                                         93.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0          Transport road - Passenger car               100.0%      8    1   \n",
       "1                             Unsupported                 0.0%      8    1   \n",
       "2          Transport road - Passenger car                99.0%      8    1   \n",
       "3          Transport road - Passenger car               100.0%      8    1   \n",
       "4                  Human voice - Shouting                93.0%      8    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0      46      10           988   66.6  64.8  \n",
       "1     0      51       7           989    NaN   NaN  \n",
       "2     0      54      51           990    NaN   NaN  \n",
       "3     1      25      17             0   65.1  64.1  \n",
       "4     1      32      56           200   73.6  71.1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "aug_ = pipeline_merge_noise.fit_transform(aug)\n",
    "event_aug = combined_event[combined_event['month'] == 8]\n",
    "merged_event_aug = pd.merge(event_aug, aug_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_aug.head()\n",
    "#merged_event_aug.to_csv('merged_event_aug.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del aug\n",
    "del event_aug\n",
    "del merged_event_aug"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "sep = pd.concat(dfs_sep, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-09-01 00:25:42.664</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>664</td>\n",
       "      <td>67.2</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-09-01 00:38:50.668</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>96.0%</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>668</td>\n",
       "      <td>67.9</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-09-01 00:39:32.668</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>668</td>\n",
       "      <td>65.3</td>\n",
       "      <td>64.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-09-01 01:57:50.692</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>692</td>\n",
       "      <td>67.7</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-09-01 02:03:06.694</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>694</td>\n",
       "      <td>66.6</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-09-01 00:25:42.664   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-09-01 00:38:50.668   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-09-01 00:39:32.668   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-09-01 01:57:50.692   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-09-01 02:03:06.694   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                        100.0   \n",
       "1                                         96.0   \n",
       "2                                        100.0   \n",
       "3                                        100.0   \n",
       "4                                        100.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0          Transport road - Passenger car               100.0%      9    1   \n",
       "1          Transport road - Passenger car                96.0%      9    1   \n",
       "2          Transport road - Passenger car               100.0%      9    1   \n",
       "3          Transport road - Passenger car               100.0%      9    1   \n",
       "4          Transport road - Passenger car               100.0%      9    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0      25      42           664   67.2  65.9  \n",
       "1     0      38      50           668   67.9  66.0  \n",
       "2     0      39      32           668   65.3  64.4  \n",
       "3     1      57      50           692   67.7  65.8  \n",
       "4     2       3       6           694   66.6  64.1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "sep_ = pipeline_merge_noise.fit_transform(sep)\n",
    "event_sep = combined_event[combined_event['month'] == 9]\n",
    "merged_event_sep = pd.merge(event_sep, sep_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_sep.head()\n",
    "#merged_event_sep.to_csv('merged_event_sep.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del sep\n",
    "del event_sep\n",
    "del merged_event_sep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "oct = pd.concat(dfs_oct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-10-01 00:13:05.578</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>578</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-10-01 01:00:04.589</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>589</td>\n",
       "      <td>72.3</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-10-01 01:01:19.590</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>590</td>\n",
       "      <td>74.8</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-10-01 01:01:27.590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>590</td>\n",
       "      <td>77.9</td>\n",
       "      <td>74.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-10-01 01:03:06.590</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>87.0%</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>590</td>\n",
       "      <td>70.5</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-10-01 00:13:05.578   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-10-01 01:00:04.589   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-10-01 01:01:19.590   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-10-01 01:01:27.590   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-10-01 01:03:06.590   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                        100.0   \n",
       "1                                        100.0   \n",
       "2                                        100.0   \n",
       "3                                          0.0   \n",
       "4                                         87.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0          Transport road - Passenger car               100.0%     10    1   \n",
       "1                  Human voice - Shouting               100.0%     10    1   \n",
       "2                  Human voice - Shouting               100.0%     10    1   \n",
       "3                             Unsupported                 0.0%     10    1   \n",
       "4                  Human voice - Shouting                87.0%     10    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0      13       5           578   66.0  65.4  \n",
       "1     1       0       4           589   72.3  68.0  \n",
       "2     1       1      19           590   74.8  69.9  \n",
       "3     1       1      27           590   77.9  74.2  \n",
       "4     1       3       6           590   70.5  67.9  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "oct_ = pipeline_merge_noise.fit_transform(oct)\n",
    "event_oct = combined_event[combined_event['month'] == 10]\n",
    "merged_event_oct = pd.merge(event_oct, oct_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_oct.head()\n",
    "#merged_event_oct.to_csv('merged_event_oct.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del oct\n",
    "del event_oct\n",
    "del merged_event_oct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "nov = pd.concat(dfs_nov, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-11-02 10:14:52.835</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>835</td>\n",
       "      <td>64.8</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-11-02 10:20:30.837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>837</td>\n",
       "      <td>74.5</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-11-02 10:33:00.840</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>840</td>\n",
       "      <td>68.8</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-11-02 10:36:26.841</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>841</td>\n",
       "      <td>65.5</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-11-02 10:42:15.843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>843</td>\n",
       "      <td>82.8</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-11-02 10:14:52.835   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-11-02 10:20:30.837   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-11-02 10:33:00.840   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-11-02 10:36:26.841   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-11-02 10:42:15.843   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                        100.0   \n",
       "1                                          0.0   \n",
       "2                                         79.0   \n",
       "3                                         95.0   \n",
       "4                                          0.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0          Transport road - Passenger car               100.0%     11    2   \n",
       "1                             Unsupported                 0.0%     11    2   \n",
       "2          Transport road - Passenger car                79.0%     11    2   \n",
       "3          Transport road - Passenger car                95.0%     11    2   \n",
       "4                             Unsupported                 0.0%     11    2   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0    10      14      52           835   64.8  64.1  \n",
       "1    10      20      30           837   74.5  67.2  \n",
       "2    10      33       0           840   68.8  66.5  \n",
       "3    10      36      26           841   65.5  64.6  \n",
       "4    10      42      15           843   82.8  77.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "nov_ = pipeline_merge_noise.fit_transform(nov)\n",
    "event_nov = combined_event[combined_event['month'] == 11]\n",
    "merged_event_nov = pd.merge(event_nov, nov_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_nov.head()\n",
    "#merged_event_nov.to_csv('merged_event_nov.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del nov\n",
    "del event_nov\n",
    "del merged_event_nov"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate noise data\n",
    "dec = pd.concat(dfs_dec, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_event_laeq_primary_detected_certainty</th>\n",
       "      <th>noise_event_laeq_primary_detected_class</th>\n",
       "      <th>certainty_percentage</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>lamax</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-12-01 00:00:55.398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unsupported</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>398</td>\n",
       "      <td>82.3</td>\n",
       "      <td>77.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-12-01 00:01:24.398</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>98.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>398</td>\n",
       "      <td>69.6</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-12-01 00:07:42.399</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Transport road - Passenger car</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>399</td>\n",
       "      <td>67.8</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-12-01 00:08:30.399</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-12-01 00:23:42.402</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Human voice - Shouting</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>402</td>\n",
       "      <td>76.7</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        result_timestamp  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim 2022-12-01 00:00:55.398   \n",
       "1  MP 01: Naamsestraat 35  Maxim 2022-12-01 00:01:24.398   \n",
       "2  MP 01: Naamsestraat 35  Maxim 2022-12-01 00:07:42.399   \n",
       "3  MP 01: Naamsestraat 35  Maxim 2022-12-01 00:08:30.399   \n",
       "4  MP 01: Naamsestraat 35  Maxim 2022-12-01 00:23:42.402   \n",
       "\n",
       "   noise_event_laeq_primary_detected_certainty  \\\n",
       "0                                          0.0   \n",
       "1                                         98.0   \n",
       "2                                         79.0   \n",
       "3                                        100.0   \n",
       "4                                         99.0   \n",
       "\n",
       "  noise_event_laeq_primary_detected_class certainty_percentage  month  day  \\\n",
       "0                             Unsupported                 0.0%     12    1   \n",
       "1          Transport road - Passenger car                98.0%     12    1   \n",
       "2          Transport road - Passenger car                79.0%     12    1   \n",
       "3                  Human voice - Shouting               100.0%     12    1   \n",
       "4                  Human voice - Shouting                99.0%     12    1   \n",
       "\n",
       "   hour  minute  second  milliseconds  lamax  laeq  \n",
       "0     0       0      55           398   82.3  77.9  \n",
       "1     0       1      24           398   69.6  66.7  \n",
       "2     0       7      42           399   67.8  66.7  \n",
       "3     0       8      30           399    NaN   NaN  \n",
       "4     0      23      42           402   76.7  72.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the data\n",
    "dec_ = pipeline_merge_noise.fit_transform(dec)\n",
    "event_dec = combined_event[combined_event['month'] == 12]\n",
    "merged_event_dec = pd.merge(event_dec, dec_, on=merge_columns,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_event_dec.head()\n",
    "#merged_event_dec.to_csv('merged_event_dec.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to reduce memory use\n",
    "del dec\n",
    "del event_dec\n",
    "del merged_event_dec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the datasets for January\n",
    "#combined_jan = pd.concat(dfs, ignore_index=True)\n",
    "#print(combined_jan.head())\n",
    "\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_jan['result_timestamp'] = pd.to_datetime(combined_jan['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_jan['month'] = combined_jan['result_timestamp'].dt.month\n",
    "#combined_jan['day'] = combined_jan['result_timestamp'].dt.day\n",
    "#combined_jan['hour'] = combined_jan['result_timestamp'].dt.hour\n",
    "#combined_jan['minute'] = combined_jan['result_timestamp'].dt.minute\n",
    "\n",
    "#combined_jan.head()\n",
    "\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_jan.columns) - set(columns_to_keep)\n",
    "#combined_jan.drop(columns=columns_to_drop, inplace=True)\n",
    "#combined_jan.head()\n",
    "\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_jan.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "#combined_jan.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "#print(combined_jan.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#jan_per_hour = combined_jan.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#jan_per_hour = jan_per_hour.reset_index()\n",
    "#jan_per_hour.head()\n",
    "\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_jan.drop('hour', axis=1, inplace=True)\n",
    "#jan_per_day= combined_jan.groupby(['month', 'day', 'description']).mean()\n",
    "#jan_per_day = jan_per_day.reset_index()\n",
    "#jan_per_day.head()\n",
    "\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_jan.drop('day', axis=1, inplace=True)\n",
    "#jan_per_month = combined_jan.groupby(['month', 'description']).mean()\n",
    "#jan_per_month = jan_per_month.reset_index()\n",
    "#jan_per_month.head()\n",
    "\n",
    "\n",
    "#del combined_jan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the datasets for February\n",
    "#combined_feb = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_feb['result_timestamp'] = pd.to_datetime(combined_feb['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_feb['month'] = combined_feb['result_timestamp'].dt.month\n",
    "#combined_feb['day'] = combined_feb['result_timestamp'].dt.day\n",
    "#combined_feb['hour'] = combined_feb['result_timestamp'].dt.hour\n",
    "#combined_feb['minute'] = combined_feb['result_timestamp'].dt.minute\n",
    "\n",
    "#combined_feb.head()\n",
    "\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_feb.columns) - set(columns_to_keep)\n",
    "#combined_feb.drop(columns=columns_to_drop, inplace=True)\n",
    "#combined_feb.head()\n",
    "\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_feb.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#feb_per_hour = combined_feb.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#feb_per_hour = feb_per_hour.reset_index()\n",
    "#print(feb_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_feb.drop('hour', axis=1, inplace=True)\n",
    "#feb_per_day = combined_feb.groupby(['month', 'day', 'description']).mean()\n",
    "#feb_per_day = feb_per_day.reset_index()\n",
    "#print(feb_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_feb.drop('day', axis=1, inplace=True)\n",
    "#feb_per_month = combined_feb.groupby(['month', 'description']).mean()\n",
    "#feb_per_month = feb_per_month.reset_index()\n",
    "#print(feb_per_month.head())\n",
    "\n",
    "#del combined_feb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#object_id</th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>lamax</th>\n",
       "      <th>lamax_unit</th>\n",
       "      <th>laeq</th>\n",
       "      <th>laeq_unit</th>\n",
       "      <th>lceq</th>\n",
       "      <th>lceq_unit</th>\n",
       "      <th>lcpeak</th>\n",
       "      <th>lcpeak_unit</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:00:00.462</td>\n",
       "      <td>60.5</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>57.9</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>63.36</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>76.57</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:00:01.462</td>\n",
       "      <td>54.1</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>53.2</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>61.86</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>74.52</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:00:02.462</td>\n",
       "      <td>61.4</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>57.5</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>64.12</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>76.46</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:00:03.462</td>\n",
       "      <td>61.3</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>59.1</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>64.68</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>76.67</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-01 00:00:04.462</td>\n",
       "      <td>61.1</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>58.4</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>64.53</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>77.07</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #object_id                    description        result_timestamp  lamax  \\\n",
       "0     255439  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:00:00.462   60.5   \n",
       "1     255439  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:00:01.462   54.1   \n",
       "2     255439  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:00:02.462   61.4   \n",
       "3     255439  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:00:03.462   61.3   \n",
       "4     255439  MP 01: Naamsestraat 35  Maxim 2022-03-01 00:00:04.462   61.1   \n",
       "\n",
       "  lamax_unit  laeq laeq_unit   lceq lceq_unit  lcpeak lcpeak_unit  month  day  \\\n",
       "0      dB(A)  57.9     dB(A)  63.36     dB(C)   76.57       dB(C)      3    1   \n",
       "1      dB(A)  53.2     dB(A)  61.86     dB(C)   74.52       dB(C)      3    1   \n",
       "2      dB(A)  57.5     dB(A)  64.12     dB(C)   76.46       dB(C)      3    1   \n",
       "3      dB(A)  59.1     dB(A)  64.68     dB(C)   76.67       dB(C)      3    1   \n",
       "4      dB(A)  58.4     dB(A)  64.53     dB(C)   77.07       dB(C)      3    1   \n",
       "\n",
       "   hour  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the datasets for March\n",
    "#combined_mar = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_mar['result_timestamp'] = pd.to_datetime(combined_mar['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_mar['month'] = combined_mar['result_timestamp'].dt.month\n",
    "#combined_mar['day'] = combined_mar['result_timestamp'].dt.day\n",
    "#combined_mar['hour'] = combined_mar['result_timestamp'].dt.hour\n",
    "#combined_mar['minute'] = combined_mar['result_timestamp'].dt.minute\n",
    "\n",
    "#combined_mar.head()\n",
    "\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_mar.columns) - set(columns_to_keep)\n",
    "#combined_mar.drop(columns=columns_to_drop, inplace=True)\n",
    "#combined_mar.head()\n",
    "\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_mar.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "#combined_mar.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "#print(combined_mar.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#mar_per_hour = combined_mar.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#mar_per_hour = mar_per_hour.reset_index()\n",
    "#print(mar_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_mar.drop('hour', axis=1, inplace=True)\n",
    "#mar_per_day = combined_mar.groupby(['month', 'day', 'description']).mean()\n",
    "#mar_per_day = mar_per_day.reset_index()\n",
    "#print(mar_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_mar.drop('day', axis=1, inplace=True)\n",
    "#mar_per_month = combined_mar.groupby(['month', 'description']).mean()\n",
    "#mar_per_month = mar_per_month.reset_index()\n",
    "#print(mar_per_month.head())\n",
    "\n",
    "#del combined_mar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#object_id</th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>lamax</th>\n",
       "      <th>lamax_unit</th>\n",
       "      <th>laeq</th>\n",
       "      <th>laeq_unit</th>\n",
       "      <th>lceq</th>\n",
       "      <th>lceq_unit</th>\n",
       "      <th>lcpeak</th>\n",
       "      <th>lcpeak_unit</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:00:00.520</td>\n",
       "      <td>62.5</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>59.3</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>64.56</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>78.13</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:00:01.520</td>\n",
       "      <td>63.3</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>61.3</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>65.35</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>78.09</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:00:02.520</td>\n",
       "      <td>61.4</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>59.1</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>64.18</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>76.63</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:00:03.510</td>\n",
       "      <td>58.9</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>56.6</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>63.58</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>75.74</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255439</td>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-04-01 00:00:04.510</td>\n",
       "      <td>59.6</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>57.2</td>\n",
       "      <td>dB(A)</td>\n",
       "      <td>63.32</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>77.86</td>\n",
       "      <td>dB(C)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #object_id                    description        result_timestamp  lamax  \\\n",
       "0     255439  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:00:00.520   62.5   \n",
       "1     255439  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:00:01.520   63.3   \n",
       "2     255439  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:00:02.520   61.4   \n",
       "3     255439  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:00:03.510   58.9   \n",
       "4     255439  MP 01: Naamsestraat 35  Maxim 2022-04-01 00:00:04.510   59.6   \n",
       "\n",
       "  lamax_unit  laeq laeq_unit   lceq lceq_unit  lcpeak lcpeak_unit  month  day  \\\n",
       "0      dB(A)  59.3     dB(A)  64.56     dB(C)   78.13       dB(C)      4    1   \n",
       "1      dB(A)  61.3     dB(A)  65.35     dB(C)   78.09       dB(C)      4    1   \n",
       "2      dB(A)  59.1     dB(A)  64.18     dB(C)   76.63       dB(C)      4    1   \n",
       "3      dB(A)  56.6     dB(A)  63.58     dB(C)   75.74       dB(C)      4    1   \n",
       "4      dB(A)  57.2     dB(A)  63.32     dB(C)   77.86       dB(C)      4    1   \n",
       "\n",
       "   hour  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the datasets \n",
    "#combined_apr = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_apr['result_timestamp'] = pd.to_datetime(combined_apr['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_apr['month'] = combined_apr['result_timestamp'].dt.month\n",
    "#combined_apr['day'] = combined_apr['result_timestamp'].dt.day\n",
    "#combined_apr['hour'] = combined_apr['result_timestamp'].dt.hour\n",
    "#combined_apr['minute'] = combined_apr['result_timestamp'].dt.minute\n",
    "\n",
    "#combined_apr.head()\n",
    "\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_apr.columns) - set(columns_to_keep)\n",
    "#combined_apr.drop(columns=columns_to_drop, inplace=True)\n",
    "#combined_apr.head()\n",
    "\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_apr.isnull().sum() / len(combined_apr))\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "#combined_apr.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "#print(combined_apr.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#apr_per_hour = combined_apr.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#apr_per_hour = apr_per_hour.reset_index()\n",
    "#print(apr_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_apr.drop('hour', axis=1, inplace=True)\n",
    "#apr_per_day = combined_apr.groupby(['month', 'day', 'description']).mean()\n",
    "#apr_per_day = apr_per_day.reset_index()\n",
    "#print(apr_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_apr.drop('day', axis=1, inplace=True)\n",
    "#apr_per_month = combined_apr.groupby(['month', 'description']).mean()\n",
    "#apr_per_month = apr_per_month.reset_index()\n",
    "#print(apr_per_month.head())\n",
    "\n",
    "#del combined_apr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description     0\n",
      "lamax          11\n",
      "laeq           11\n",
      "month           0\n",
      "day             0\n",
      "hour            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combining the datasets \n",
    "#combined_may = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_may['result_timestamp'] = pd.to_datetime(combined_may['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_may['month'] = combined_may['result_timestamp'].dt.month\n",
    "#combined_may['day'] = combined_may['result_timestamp'].dt.day\n",
    "#combined_may['hour'] = combined_may['result_timestamp'].dt.hour\n",
    "#combined_may['minute'] = combined_may['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_may.columns) - set(columns_to_keep)\n",
    "#combined_may.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_may.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "#combined_may.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "#print(combined_may.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#may_per_hour = combined_may.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#may_per_hour = may_per_hour.reset_index()\n",
    "#print(may_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_may.drop('hour', axis=1, inplace=True)\n",
    "#may_per_day = combined_may.groupby(['month', 'day', 'description']).mean()\n",
    "#may_per_day = may_per_day.reset_index()\n",
    "#print(may_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_may.drop('day', axis=1, inplace=True)\n",
    "#may_per_month = combined_may.groupby(['month', 'description']).mean()\n",
    "#may_per_month = may_per_month.reset_index()\n",
    "#print(may_per_month.head())\n",
    "\n",
    "#del combined_may"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    0\n",
      "lamax          0\n",
      "laeq           0\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combining the datasets \n",
    "#combined_jun = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_jun['result_timestamp'] = pd.to_datetime(combined_jun['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_jun['month'] = combined_jun['result_timestamp'].dt.month\n",
    "#combined_jun['day'] = combined_jun['result_timestamp'].dt.day\n",
    "#combined_jun['hour'] = combined_jun['result_timestamp'].dt.hour\n",
    "#combined_jun['minute'] = combined_jun['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_jun.columns) - set(columns_to_keep)\n",
    "#combined_jun.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_jun.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#jun_per_hour = combined_jun.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#jun_per_hour = jun_per_hour.reset_index()\n",
    "#print(jun_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_jun.drop('hour', axis=1, inplace=True)\n",
    "#jun_per_day = combined_jun.groupby(['month', 'day', 'description']).mean()\n",
    "#jun_per_day = jun_per_day.reset_index()\n",
    "#print(jun_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_jun.drop('day', axis=1, inplace=True)\n",
    "#jun_per_month = combined_jun.groupby(['month', 'description']).mean()\n",
    "#jun_per_month = jun_per_month.reset_index()\n",
    "#print(jun_per_month.head())\n",
    "\n",
    "#del combined_jun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    0\n",
      "lamax          5\n",
      "laeq           5\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combining the datasets for \n",
    "#combined_jul = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_jul['result_timestamp'] = pd.to_datetime(combined_jul['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_jul['month'] = combined_jul['result_timestamp'].dt.month\n",
    "#combined_jul['day'] = combined_jul['result_timestamp'].dt.day\n",
    "#combined_jul['hour'] = combined_jul['result_timestamp'].dt.hour\n",
    "#combined_jul['minute'] = combined_jul['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_jul.columns) - set(columns_to_keep)\n",
    "#combined_jul.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_jul.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "#combined_jul.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "#print(combined_jul.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#jul_per_hour = combined_jul.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#jul_per_hour = jul_per_hour.reset_index()\n",
    "#print(jul_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_jul.drop('hour', axis=1, inplace=True)\n",
    "#jul_per_day = combined_jul.groupby(['month', 'day', 'description']).mean()\n",
    "#jul_per_day = jul_per_day.reset_index()\n",
    "#print(jul_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_jul.drop('day', axis=1, inplace=True)\n",
    "#jul_per_month = combined_jul.groupby(['month', 'description']).mean()\n",
    "#jul_per_month = jul_per_month.reset_index()\n",
    "#print(jul_per_month.head())\n",
    "\n",
    "#del combined_jul"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    0\n",
      "lamax          0\n",
      "laeq           0\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combining the datasets for\n",
    "#combined_aug = pd.concat(dfs, ignore_index=True)\n",
    "#del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "#combined_aug['result_timestamp'] = pd.to_datetime(combined_aug['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "#combined_aug['month'] = combined_aug['result_timestamp'].dt.month\n",
    "#combined_aug['day'] = combined_aug['result_timestamp'].dt.day\n",
    "#combined_aug['hour'] = combined_aug['result_timestamp'].dt.hour\n",
    "#combined_aug['minute'] = combined_aug['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "#columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "#columns_to_drop = set(combined_aug.columns) - set(columns_to_keep)\n",
    "#combined_aug.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "#print(combined_aug.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "#aug_per_hour = combined_aug.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "#aug_per_hour = aug_per_hour.reset_index()\n",
    "#print(aug_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "#combined_aug.drop('hour', axis=1, inplace=True)\n",
    "#aug_per_day = combined_aug.groupby(['month', 'day', 'description']).mean()\n",
    "#aug_per_day = aug_per_day.reset_index()\n",
    "#print(aug_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "#combined_aug.drop('day', axis=1, inplace=True)\n",
    "#aug_per_month = combined_aug.groupby(['month', 'description']).mean()\n",
    "#aug_per_month = aug_per_month.reset_index()\n",
    "#print(aug_per_month.head())\n",
    "\n",
    "#del combined_aug"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description     0\n",
      "lamax           2\n",
      "laeq           12\n",
      "month           0\n",
      "day             0\n",
      "hour            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Combining the datasets \n",
    "combined_sep = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "combined_sep['result_timestamp'] = pd.to_datetime(combined_sep['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "combined_sep['month'] = combined_sep['result_timestamp'].dt.month\n",
    "combined_sep['day'] = combined_sep['result_timestamp'].dt.day\n",
    "combined_sep['hour'] = combined_sep['result_timestamp'].dt.hour\n",
    "#combined_sep['minute'] = combined_sep['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "columns_to_drop = set(combined_sep.columns) - set(columns_to_keep)\n",
    "combined_sep.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_sep.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "combined_sep.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "print(combined_sep.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "sep_per_hour = combined_sep.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "sep_per_hour = sep_per_hour.reset_index()\n",
    "print(sep_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "combined_sep.drop('hour', axis=1, inplace=True)\n",
    "sep_per_day = combined_sep.groupby(['month', 'day', 'description']).mean()\n",
    "sep_per_day = sep_per_day.reset_index()\n",
    "print(sep_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "combined_sep.drop('day', axis=1, inplace=True)\n",
    "sep_per_month = combined_sep.groupby(['month', 'description']).mean()\n",
    "sep_per_month = sep_per_month.reset_index()\n",
    "print(sep_per_month.head())\n",
    "\n",
    "del combined_sep\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description     0\n",
      "lamax          10\n",
      "laeq           10\n",
      "month           0\n",
      "day             0\n",
      "hour            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Combining the datasets \n",
    "combined_oct = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "combined_oct['result_timestamp'] = pd.to_datetime(combined_oct['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "combined_oct['month'] = combined_oct['result_timestamp'].dt.month\n",
    "combined_oct['day'] = combined_oct['result_timestamp'].dt.day\n",
    "combined_oct['hour'] = combined_oct['result_timestamp'].dt.hour\n",
    "#combined_oct['minute'] = combined_oct['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "columns_to_drop = set(combined_oct.columns) - set(columns_to_keep)\n",
    "combined_oct.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_oct.isnull().sum())\n",
    "\n",
    "\n",
    "# forward fill missing values \n",
    "combined_oct.ffill(inplace=True)\n",
    "\n",
    "# check whether there are missing values left\n",
    "print(combined_oct.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "oct_per_hour = combined_oct.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "oct_per_hour = oct_per_hour.reset_index()\n",
    "print(oct_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "combined_oct.drop('hour', axis=1, inplace=True)\n",
    "oct_per_day = combined_oct.groupby(['month', 'day', 'description']).mean()\n",
    "oct_per_day = oct_per_day.reset_index()\n",
    "print(oct_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "combined_oct.drop('day', axis=1, inplace=True)\n",
    "oct_per_month = combined_oct.groupby(['month', 'description']).mean()\n",
    "oct_per_month = oct_per_month.reset_index()\n",
    "print(oct_per_month.head())\n",
    "\n",
    "del combined_oct\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    0\n",
      "lamax          0\n",
      "laeq           0\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''''\n",
    "# Combining the datasets \n",
    "combined_nov = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "combined_nov['result_timestamp'] = pd.to_datetime(combined_nov['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "combined_nov['month'] = combined_nov['result_timestamp'].dt.month\n",
    "combined_nov['day'] = combined_nov['result_timestamp'].dt.day\n",
    "combined_nov['hour'] = combined_nov['result_timestamp'].dt.hour\n",
    "#combined_nov['minute'] = combined_nov['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "columns_to_drop = set(combined_nov.columns) - set(columns_to_keep)\n",
    "combined_nov.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_nov.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "nov_per_hour = combined_nov.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "nov_per_hour = nov_per_hour.reset_index()\n",
    "print(nov_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "combined_nov.drop('hour', axis=1, inplace=True)\n",
    "nov_per_day = combined_nov.groupby(['month', 'day', 'description']).mean()\n",
    "nov_per_day = nov_per_day.reset_index()\n",
    "print(nov_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "combined_nov.drop('day', axis=1, inplace=True)\n",
    "nov_per_month = combined_nov.groupby(['month', 'description']).mean()\n",
    "nov_per_month = nov_per_month.reset_index()\n",
    "print(nov_per_month.head())\n",
    "\n",
    "del combined_nov\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    0\n",
      "lamax          0\n",
      "laeq           0\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Combining the datasets \n",
    "combined_dec = pd.concat(dfs, ignore_index=True)\n",
    "del dfs # deleting the separate dataframes to minimize memory usage\n",
    "\n",
    "# extract the month, day, hour, minute of \"result_timestamp\"\n",
    "combined_dec['result_timestamp'] = pd.to_datetime(combined_dec['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "combined_dec['month'] = combined_dec['result_timestamp'].dt.month\n",
    "combined_dec['day'] = combined_dec['result_timestamp'].dt.day\n",
    "combined_dec['hour'] = combined_dec['result_timestamp'].dt.hour\n",
    "#combined_dec['minute'] = combined_dec['result_timestamp'].dt.minute\n",
    "\n",
    "# Drop the columns we won't use\n",
    "columns_to_keep = ['description', 'lamax', 'laeq', 'month', 'day', 'hour'] #also minute if we calculate it\n",
    "columns_to_drop = set(combined_dec.columns) - set(columns_to_keep)\n",
    "combined_dec.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# check for missing values in each column\n",
    "print(combined_dec.isnull().sum())\n",
    "\n",
    "\n",
    "# Create dataframe per hour\n",
    "dec_per_hour = combined_dec.groupby(['month', 'day', 'hour', 'description']).mean()\n",
    "dec_per_hour = dec_per_hour.reset_index()\n",
    "print(dec_per_hour.head())\n",
    "\n",
    "# Create dataframe per day\n",
    "combined_dec.drop('hour', axis=1, inplace=True)\n",
    "dec_per_day = combined_dec.groupby(['month', 'day', 'description']).mean()\n",
    "dec_per_day = dec_per_day.reset_index()\n",
    "print(dec_per_day.head())\n",
    "\n",
    "# Create dataframe per month\n",
    "combined_dec.drop('day', axis=1, inplace=True)\n",
    "dec_per_month = combined_dec.groupby(['month', 'description']).mean()\n",
    "dec_per_month = dec_per_month.reset_index()\n",
    "print(dec_per_month.head())\n",
    "\n",
    "del combined_dec\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have exported the preprocessed dataframes for the noise and weather data of 2022, we can just use these files instead of loading all 112 files from the S3 bucket each time, as this takes a lot of time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD PREPROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data from the S3 bucket (don't forget to pip install boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # meteo data\n",
    "# Q1_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q1.csv')\n",
    "# Q2_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q2.csv')\n",
    "# Q3_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q3.csv')\n",
    "# Q4_2022 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Meteo+data/LC_2022Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: this is the 'old' noise data, don't run this\n",
    "\n",
    "# noise data\n",
    "# exp40_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp40_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp40_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp40_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp40_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp40_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp40_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp40_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp40_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_40/csv_results_40_303910_mp-04-his-hears.csv', header=0, sep=';')\n",
    "\n",
    "# exp41_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp41_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp41_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp41_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp41_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp41_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp41_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp41_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp41_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_41/csv_results_41_303910_mp-04-his-hears.csv', header=0, sep=';')\n",
    "\n",
    "# exp42_naamse35 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# exp42_naamse57 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# exp42_naamse62 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# exp42_calvarie = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# exp42_naamse81 = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# exp42_park = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# exp42_kiosk = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# exp42_vrijt = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# exp42_his = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/export_42/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_columns = [\"#object_id\", \"description\", \"result_timestamp\", \"lamax\", \"laeq\"]\n",
    "# naamse35_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';', usecols=noise_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - January\n",
    "# naamse35_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jan = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jan/Jan/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - February\n",
    "# naamse35_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_feb = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Feb/Feb/csv_results_42_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - March\n",
    "# naamse35_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_mar = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/March/March/csv_results_44_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - April\n",
    "# naamse35_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_apr = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/April/April/csv_results_45_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - May\n",
    "# naamse35_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_may = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/May/May/csv_results_46_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - June\n",
    "# naamse35_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jun = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/June/June/csv_results_47_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - July\n",
    "# naamse35_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_jul = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Jul/Jul/csv_results_48_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - August\n",
    "# naamse35_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_aug = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Aug/Aug/csv_results_49_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - September\n",
    "# naamse35_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_sep = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Sep/Sep/csv_results_50_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - October\n",
    "# naamse35_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_oct = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Oct/Oct/csv_results_51_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - November\n",
    "# naamse35_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_nov = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Nov/Nov/csv_results_52_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updated noise data - December\n",
    "# naamse35_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255439_mp-01-naamsestraat-35-maxim.csv', header=0, sep=';')\n",
    "# naamse57_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255440_mp-02-naamsestraat-57-xior.csv', header=0, sep=';')\n",
    "# naamse62_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255441_mp-03-naamsestraat-62-taste.csv', header=0, sep=';')\n",
    "# calvarie_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255442_mp-05-calvariekapel-ku-leuven.csv', header=0, sep=';')\n",
    "# park_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255443_mp-06-parkstraat-2-la-filosovia.csv', header=0, sep=';')\n",
    "# naamse81_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255444_mp-07-naamsestraat-81.csv', header=0, sep=';')\n",
    "# kiosk_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_255445_mp-08-kiosk-stadspark.csv', header=0, sep=';')\n",
    "# vrijt_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_280324_mp08bis---vrijthof.csv', header=0, sep=';')\n",
    "# his_dec = pd.read_csv('https://mda-georgia-bucket.s3.eu-central-1.amazonaws.com/Noise+data/Dec/Dec/csv_results_53_303910_mp-04-his-hears.csv', header=0, sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining and aggregating the meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine meteo dataset \n",
    "# meteocombined = pd.concat([Q1_2022, Q2_2022, Q3_2022, Q4_2022], axis=0)\n",
    "# meteocombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "# print(meteocombined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate meteo data by day\n",
    "# avg_meteo_combined = meteocombined.groupby(['Year','Month', 'Day']).mean()\n",
    "# avg_meteo_combined = avg_meteo_combined.reset_index()\n",
    "# avg_meteo_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_max_value = avg_meteo_combined['Month'].max()\n",
    "# print(f\"This combined meteo dataset contains the weather data for all {month_max_value} months.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining and aggregating the noise data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for January together\n",
    "# noise_jan_combined = pd.concat([naamse35_jan, naamse57_jan, naamse62_jan, calvarie_jan, park_jan, naamse81_jan, kiosk_jan, vrijt_jan, his_jan], axis=0)\n",
    "# noise_jan_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jan_combined['result_timestamp'] = pd.to_datetime(noise_jan_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jan_combined['result_date'] = noise_jan_combined['result_timestamp'].dt.date\n",
    "# noise_jan_combined['result_month'] = noise_jan_combined['result_timestamp'].dt.month\n",
    "# noise_jan_combined['result_day'] = noise_jan_combined['result_timestamp'].dt.day\n",
    "# noise_jan_combined['result_hour'] = noise_jan_combined['result_timestamp'].dt.hour\n",
    "# noise_jan_combined['result_minute'] = noise_jan_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jan_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_jan_combined = noise_jan_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jan_combined = avg_jan_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jan_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jan_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "# print(avg_jan_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for February together\n",
    "# noise_feb_combined = pd.concat([naamse35_feb, naamse57_feb, naamse62_feb, calvarie_feb, park_feb, naamse81_feb, kiosk_feb, vrijt_feb, his_feb], axis=0)\n",
    "# noise_feb_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_feb_combined['result_timestamp'] = pd.to_datetime(noise_feb_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_feb_combined['result_date'] = noise_feb_combined['result_timestamp'].dt.date\n",
    "# noise_feb_combined['result_month'] = noise_feb_combined['result_timestamp'].dt.month\n",
    "# noise_feb_combined['result_day'] = noise_feb_combined['result_timestamp'].dt.day\n",
    "# noise_feb_combined['result_hour'] = noise_feb_combined['result_timestamp'].dt.hour\n",
    "# noise_feb_combined['result_minute'] = noise_feb_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_feb_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_feb_combined = noise_feb_combined.groupby(['result_date','description']).mean()\n",
    "# avg_feb_combined = avg_feb_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_feb_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_feb_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_feb_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for March together\n",
    "# noise_mar_combined = pd.concat([naamse35_mar, naamse57_mar, naamse62_mar, calvarie_mar, park_mar, naamse81_mar, kiosk_mar, vrijt_mar, his_mar], axis=0)\n",
    "# noise_mar_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_mar_combined['result_timestamp'] = pd.to_datetime(noise_mar_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_mar_combined['result_date'] = noise_mar_combined['result_timestamp'].dt.date\n",
    "# noise_mar_combined['result_month'] = noise_mar_combined['result_timestamp'].dt.month\n",
    "# noise_mar_combined['result_day'] = noise_mar_combined['result_timestamp'].dt.day\n",
    "# noise_mar_combined['result_hour'] = noise_mar_combined['result_timestamp'].dt.hour\n",
    "# noise_mar_combined['result_minute'] = noise_mar_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_mar_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_mar_combined = noise_mar_combined.groupby(['result_date','description']).mean()\n",
    "# avg_mar_combined = avg_mar_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_mar_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_mar_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_mar_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- April "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for April together\n",
    "# noise_apr_combined = pd.concat([naamse35_apr, naamse57_apr, naamse62_apr, calvarie_apr, park_apr, naamse81_apr, kiosk_apr, vrijt_apr, his_apr], axis=0)\n",
    "# noise_apr_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_apr_combined['result_timestamp'] = pd.to_datetime(noise_apr_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_apr_combined['result_date'] = noise_apr_combined['result_timestamp'].dt.date\n",
    "# noise_apr_combined['result_month'] = noise_apr_combined['result_timestamp'].dt.month\n",
    "# noise_apr_combined['result_day'] = noise_apr_combined['result_timestamp'].dt.day\n",
    "# noise_apr_combined['result_hour'] = noise_apr_combined['result_timestamp'].dt.hour\n",
    "# noise_apr_combined['result_minute'] = noise_apr_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_apr_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_apr_combined = noise_apr_combined.groupby(['result_date','description']).mean()\n",
    "# avg_apr_combined = avg_apr_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_apr_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_apr_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_apr_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for May together\n",
    "# noise_may_combined = pd.concat([naamse35_may, naamse57_may, naamse62_may, calvarie_may, park_may, naamse81_may, kiosk_may, vrijt_may, his_may], axis=0)\n",
    "# noise_may_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_may_combined['result_timestamp'] = pd.to_datetime(noise_may_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_may_combined['result_date'] = noise_may_combined['result_timestamp'].dt.date\n",
    "# noise_may_combined['result_month'] = noise_may_combined['result_timestamp'].dt.month\n",
    "# noise_may_combined['result_day'] = noise_may_combined['result_timestamp'].dt.day\n",
    "# noise_may_combined['result_hour'] = noise_may_combined['result_timestamp'].dt.hour\n",
    "# noise_may_combined['result_minute'] = noise_may_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_may_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_may_combined = noise_may_combined.groupby(['result_date','description']).mean()\n",
    "# avg_may_combined = avg_may_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_may_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_may_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_may_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for June together\n",
    "# noise_jun_combined = pd.concat([naamse35_jun, naamse57_jun, naamse62_jun, calvarie_jun, park_jun, naamse81_jun, kiosk_jun, vrijt_jun, his_jun], axis=0)\n",
    "# noise_jun_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jun_combined['result_timestamp'] = pd.to_datetime(noise_jun_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jun_combined['result_date'] = noise_jun_combined['result_timestamp'].dt.date\n",
    "# noise_jun_combined['result_month'] = noise_jun_combined['result_timestamp'].dt.month\n",
    "# noise_jun_combined['result_day'] = noise_jun_combined['result_timestamp'].dt.day\n",
    "# noise_jun_combined['result_hour'] = noise_jun_combined['result_timestamp'].dt.hour\n",
    "# noise_jun_combined['result_minute'] = noise_jun_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jun_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data by day\n",
    "# avg_jun_combined = noise_jun_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jun_combined = avg_jun_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jun_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jun_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_jun_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for July together\n",
    "# noise_jul_combined = pd.concat([naamse35_jul, naamse57_jul, naamse62_jul, calvarie_jul, park_jul, naamse81_jul, kiosk_jul, vrijt_jul, his_jul], axis=0)\n",
    "# noise_jul_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_jul_combined['result_timestamp'] = pd.to_datetime(noise_jul_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_jul_combined['result_date'] = noise_jul_combined['result_timestamp'].dt.date\n",
    "# noise_jul_combined['result_month'] = noise_jul_combined['result_timestamp'].dt.month\n",
    "# noise_jul_combined['result_day'] = noise_jul_combined['result_timestamp'].dt.day\n",
    "# noise_jul_combined['result_hour'] = noise_jul_combined['result_timestamp'].dt.hour\n",
    "# noise_jul_combined['result_minute'] = noise_jul_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_jul_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_jul_combined = noise_jul_combined.groupby(['result_date','description']).mean()\n",
    "# avg_jul_combined = avg_jul_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_jul_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_jul_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_jul_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for August together\n",
    "# noise_aug_combined = pd.concat([naamse35_aug, naamse57_aug, naamse62_aug, calvarie_aug, park_aug, naamse81_aug, kiosk_aug, vrijt_aug, his_aug], axis=0)\n",
    "# noise_aug_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_aug_combined['result_timestamp'] = pd.to_datetime(noise_aug_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_aug_combined['result_date'] = noise_aug_combined['result_timestamp'].dt.date\n",
    "# noise_aug_combined['result_month'] = noise_aug_combined['result_timestamp'].dt.month\n",
    "# noise_aug_combined['result_day'] = noise_aug_combined['result_timestamp'].dt.day\n",
    "# noise_aug_combined['result_hour'] = noise_aug_combined['result_timestamp'].dt.hour\n",
    "# noise_aug_combined['result_minute'] = noise_aug_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_aug_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_aug_combined = noise_aug_combined.groupby(['result_date','description']).mean()\n",
    "# avg_aug_combined = avg_aug_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_aug_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_aug_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_aug_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for September together\n",
    "# noise_sep_combined = pd.concat([naamse35_sep, naamse57_sep, naamse62_sep, calvarie_sep, park_sep, naamse81_sep, kiosk_sep, vrijt_sep, his_sep], axis=0)\n",
    "# noise_sep_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_sep_combined['result_timestamp'] = pd.to_datetime(noise_sep_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_sep_combined['result_date'] = noise_sep_combined['result_timestamp'].dt.date\n",
    "# noise_sep_combined['result_month'] = noise_sep_combined['result_timestamp'].dt.month\n",
    "# noise_sep_combined['result_day'] = noise_sep_combined['result_timestamp'].dt.day\n",
    "# noise_sep_combined['result_hour'] = noise_sep_combined['result_timestamp'].dt.hour\n",
    "# noise_sep_combined['result_minute'] = noise_sep_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_sep_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_sep_combined = noise_sep_combined.groupby(['result_date','description']).mean()\n",
    "# avg_sep_combined = avg_sep_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_sep_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_sep_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_sep_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for Octber together\n",
    "# noise_oct_combined = pd.concat([naamse35_oct, naamse57_oct, naamse62_oct, calvarie_oct, park_oct, naamse81_oct, kiosk_oct, vrijt_oct, his_oct], axis=0)\n",
    "# noise_oct_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_oct_combined['result_timestamp'] = pd.to_datetime(noise_oct_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_oct_combined['result_date'] = noise_oct_combined['result_timestamp'].dt.date\n",
    "# noise_oct_combined['result_month'] = noise_oct_combined['result_timestamp'].dt.month\n",
    "# noise_oct_combined['result_day'] = noise_oct_combined['result_timestamp'].dt.day\n",
    "# noise_oct_combined['result_hour'] = noise_oct_combined['result_timestamp'].dt.hour\n",
    "# noise_oct_combined['result_minute'] = noise_oct_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_oct_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_oct_combined = noise_oct_combined.groupby(['result_date','description']).mean()\n",
    "# avg_oct_combined = avg_oct_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_oct_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_oct_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_oct_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for November together\n",
    "# noise_nov_combined = pd.concat([naamse35_nov, naamse57_nov, naamse62_nov, calvarie_nov, park_nov, naamse81_nov, kiosk_nov, vrijt_nov, his_nov], axis=0)\n",
    "# noise_nov_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_nov_combined['result_timestamp'] = pd.to_datetime(noise_nov_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_nov_combined['result_date'] = noise_nov_combined['result_timestamp'].dt.date\n",
    "# noise_nov_combined['result_month'] = noise_nov_combined['result_timestamp'].dt.month\n",
    "# noise_nov_combined['result_day'] = noise_nov_combined['result_timestamp'].dt.day\n",
    "# noise_nov_combined['result_hour'] = noise_nov_combined['result_timestamp'].dt.hour\n",
    "# noise_nov_combined['result_minute'] = noise_nov_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_nov_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_nov_combined = noise_nov_combined.groupby(['result_date','description']).mean()\n",
    "# avg_nov_combined = avg_nov_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_nov_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_nov_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_nov_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine noise data for December together\n",
    "# noise_dec_combined = pd.concat([naamse35_dec, naamse57_dec, naamse62_dec, calvarie_dec, park_dec, naamse81_dec, kiosk_dec, vrijt_dec, his_dec], axis=0)\n",
    "# noise_dec_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract the date, month, hour, minute of \"result_timestamp\"\n",
    "# noise_dec_combined['result_timestamp'] = pd.to_datetime(noise_dec_combined['result_timestamp'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# noise_dec_combined['result_date'] = noise_dec_combined['result_timestamp'].dt.date\n",
    "# noise_dec_combined['result_month'] = noise_dec_combined['result_timestamp'].dt.month\n",
    "# noise_dec_combined['result_day'] = noise_dec_combined['result_timestamp'].dt.day\n",
    "# noise_dec_combined['result_hour'] = noise_dec_combined['result_timestamp'].dt.hour\n",
    "# noise_dec_combined['result_minute'] = noise_dec_combined['result_timestamp'].dt.minute\n",
    "\n",
    "# noise_dec_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate the data by day\n",
    "# avg_dec_combined = noise_dec_combined.groupby(['result_date','description']).mean()\n",
    "# avg_dec_combined = avg_dec_combined.reset_index()\n",
    "# columns_to_drop = ['result_hour', 'result_minute']\n",
    "# avg_dec_combined.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# avg_dec_combined.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values in each column\n",
    "# print(avg_dec_combined.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining monthly noise level datasets into a yearly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the monthly datasets\n",
    "datasets = [avg_jan_combined, avg_feb_combined, avg_mar_combined, avg_apr_combined, avg_may_combined, avg_jun_combined, avg_jul_combined, avg_aug_combined, avg_sep_combined, avg_oct_combined, avg_nov_combined, avg_dec_combined]\n",
    "\n",
    "# Concatenate the datasets vertically\n",
    "avg_year_combined = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Sort the combined dataset by 'result_date' in ascending order\n",
    "avg_year_combined.sort_values(by='result_date', inplace=True)\n",
    "\n",
    "# Reset the index of the combined dataset\n",
    "avg_year_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the combined and sorted yearly dataset\n",
    "avg_year_combined.head(2000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
